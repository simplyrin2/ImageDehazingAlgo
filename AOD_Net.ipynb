{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class AODNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AODNet, self).__init__()\n",
    "        self.b = nn.Parameter(torch.scalar_tensor(1))\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 3, kernel_size=1, padding=0, stride=1)\n",
    "        self.conv2 = nn.Conv2d(3, 3, kernel_size=3, padding=1, stride=1)\n",
    "        self.conv3 = nn.Conv2d(6, 3, kernel_size=5, padding=2, stride=1)\n",
    "        self.conv4 = nn.Conv2d(6, 3, kernel_size=7, padding=3, stride=1)\n",
    "        self.conv5 = nn.Conv2d(12, 3, kernel_size=3, padding=1, stride=1)\n",
    "\n",
    "# The AOD-Net consists of five\n",
    "# \"concatl \" layer of AOD-Net concatenates features from the layers \"convl \" and \"conv2 \". Similarly, \"concat2 \" concatenates those from \"conv2\" and \"conv3 \"; \"concat3\" concatenates those from \"convl\", \"conv2\", \"conv3\", and \"conv4\". The kernel \"K\" is learned from the concatenated features. The output of the AOD-Net is the weighted sum of the input image and the kernel \"K\" minus \"K\" itself.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 =  nn.functional.relu(self.conv1(x))\n",
    "        x2 =  nn.functional.relu(self.conv2(x1))\n",
    "        concat1 = torch.cat((x1, x2), 1)\n",
    "        x3 = nn.functional.relu(self.conv3(concat1))\n",
    "        concat2 = torch.cat((x2, x3), 1)\n",
    "        x4 = nn.functional.relu(self.conv4(concat2))\n",
    "        concat3 = torch.cat((x1, x2, x3, x4), 1)\n",
    "        K = nn.functional.relu(self.conv5(concat3))\n",
    "\n",
    "        output = torch.mul(K, x) - K + self.b\n",
    "        return output\n",
    "    \n",
    "# Loss Function\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "def create_training_set(original_img_data_path, hazy_img_data_path):\n",
    "    train_list = []\n",
    "    val_list = []\n",
    "    \n",
    "    hazy_img_list = glob.glob(hazy_img_data_path + '*.jpg')\n",
    "\n",
    "    d = {}\n",
    "    for img in hazy_img_list:\n",
    "        i = img.split('\\\\')[-1]\n",
    "        key = i.split('_')[0] + '_' + i.split('_')[1] + \".jpg\"\n",
    "        if key in d.keys():\n",
    "            d[key].append(img.split('\\\\')[-1])\n",
    "        else:\n",
    "            d[key] = [img.split('\\\\')[-1]]\n",
    "    \n",
    "    train_imgs = []\n",
    "    val_imgs = []\n",
    "\n",
    "    for i in range(len(d.keys())):\n",
    "        if i < 0.9 * len(d.keys()):\n",
    "            train_imgs.append(list(d.keys())[i])\n",
    "        else:\n",
    "            val_imgs.append(list(d.keys())[i])\n",
    "\n",
    "    for key in list(d.keys()):\n",
    "        if key in train_imgs:\n",
    "            for hazy_img in d[key]:\n",
    "                train_list.append((original_img_data_path + key, hazy_img_data_path + hazy_img))\n",
    "        else:\n",
    "            for hazy_img in d[key]:\n",
    "                val_list.append((original_img_data_path + key, hazy_img_data_path + hazy_img))\n",
    "    random.shuffle(train_list)\n",
    "    random.shuffle(val_list)\n",
    "    return train_list, val_list\n",
    "\n",
    "class create_dataloader(Dataset):\n",
    "    def __init__(self, org_img_path, hazy_img_path, mode=\"train\"):\n",
    "        self.train_list, self.val_list = create_training_set(org_img_path, hazy_img_path)\n",
    "        if mode == \"train\":\n",
    "            self.data_list = self.train_list\n",
    "            print('Total training images:', len(self.data_list))\n",
    "        else:\n",
    "            self.data_list = self.val_list\n",
    "            print('Total validation images:', len(self.data_list))\n",
    "    \n",
    "    def transform(self, img):\n",
    "        return torch.from_numpy(np.asarray(img.resize((480, 640), Image.Resampling.BILINEAR))).permute(2, 0, 1).float() / 255.0\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        org_img_path, hazy_img_path = self.data_list[idx]\n",
    "        org_img = Image.open(org_img_path)\n",
    "        hazy_img = Image.open(hazy_img_path)\n",
    "        org_img = self.transform(org_img)\n",
    "        hazy_img = self.transform(hazy_img)\n",
    "        return org_img, hazy_img\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "def train(config):\n",
    "    def weights_init(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    # Hyperparameters\n",
    "    num_epochs = config['num_epochs']\n",
    "    batch_size = config['batch_size']\n",
    "    learning_rate = config['learning_rate']\n",
    "    weight_decay = config['weight_decay']\n",
    "    grad_clip_norm = config['grad_clip_norm']\n",
    "\n",
    "    # Data loader\n",
    "    train_dataset = create_dataloader(config['original_img_data_path'], config['hazy_img_data_path'], mode=\"train\")\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    val_dataset = create_dataloader(config['original_img_data_path'], config['hazy_img_data_path'], mode=\"val\")\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Model\n",
    "    model = AODNet()\n",
    "    model.apply(weights_init)\n",
    "    model.to(device)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Train the model\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (org_img, hazy_img) in enumerate(train_loader):\n",
    "            org_img = org_img.to(device)\n",
    "            hazy_img = hazy_img.to(device)\n",
    "            \n",
    "            clean_img = model(hazy_img)\n",
    "            loss = loss_fn(clean_img, org_img)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % config['display_iter'] == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            if (i+1) % config['save_iter'] == 0:\n",
    "                torch.save(model.state_dict(), config['model_path'] + 'model-{}.ckpt'.format(epoch+1))\n",
    "\n",
    "        # Validation\n",
    "        for i, (org_img, hazy_img) in enumerate(val_loader):\n",
    "            org_img = org_img.to(device)\n",
    "            hazy_img = hazy_img.to(device)\n",
    "\n",
    "            clean_img = model(hazy_img)\n",
    "            loss = loss_fn(clean_img, org_img)\n",
    "\n",
    "            torchvision.utils.save_image(torch.cat((hazy_img, clean_img, org_img),0), config['output_path'] + 'clean_img_{}.jpg'.format(i))\n",
    "        torch.save(model.state_dict(), 'model-{}.ckpt'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training images: 24443\n",
      "Total validation images: 2813\n",
      "Epoch [1/10], Step [100/3056], Loss: 0.3082\n",
      "Epoch [1/10], Step [200/3056], Loss: 0.1782\n",
      "Epoch [1/10], Step [300/3056], Loss: 0.1302\n",
      "Epoch [1/10], Step [400/3056], Loss: 0.1239\n",
      "Epoch [1/10], Step [500/3056], Loss: 0.1300\n",
      "Epoch [1/10], Step [600/3056], Loss: 0.1414\n",
      "Epoch [1/10], Step [700/3056], Loss: 0.1413\n",
      "Epoch [1/10], Step [800/3056], Loss: 0.1152\n",
      "Epoch [1/10], Step [900/3056], Loss: 0.1102\n",
      "Epoch [1/10], Step [1000/3056], Loss: 0.1447\n",
      "Epoch [1/10], Step [1100/3056], Loss: 0.1147\n",
      "Epoch [1/10], Step [1200/3056], Loss: 0.1232\n",
      "Epoch [1/10], Step [1300/3056], Loss: 0.1242\n",
      "Epoch [1/10], Step [1400/3056], Loss: 0.0877\n",
      "Epoch [1/10], Step [1500/3056], Loss: 0.1023\n",
      "Epoch [1/10], Step [1600/3056], Loss: 0.1150\n",
      "Epoch [1/10], Step [1700/3056], Loss: 0.0776\n",
      "Epoch [1/10], Step [1800/3056], Loss: 0.0872\n",
      "Epoch [1/10], Step [1900/3056], Loss: 0.0905\n",
      "Epoch [1/10], Step [2000/3056], Loss: 0.0695\n",
      "Epoch [1/10], Step [2100/3056], Loss: 0.0717\n",
      "Epoch [1/10], Step [2200/3056], Loss: 0.0818\n",
      "Epoch [1/10], Step [2300/3056], Loss: 0.1026\n",
      "Epoch [1/10], Step [2400/3056], Loss: 0.0949\n",
      "Epoch [1/10], Step [2500/3056], Loss: 0.0871\n",
      "Epoch [1/10], Step [2600/3056], Loss: 0.0880\n",
      "Epoch [1/10], Step [2700/3056], Loss: 0.0898\n",
      "Epoch [1/10], Step [2800/3056], Loss: 0.0751\n",
      "Epoch [1/10], Step [2900/3056], Loss: 0.0837\n",
      "Epoch [1/10], Step [3000/3056], Loss: 0.0690\n",
      "Epoch [2/10], Step [100/3056], Loss: 0.0688\n",
      "Epoch [2/10], Step [200/3056], Loss: 0.0689\n",
      "Epoch [2/10], Step [300/3056], Loss: 0.0820\n",
      "Epoch [2/10], Step [400/3056], Loss: 0.0919\n",
      "Epoch [2/10], Step [500/3056], Loss: 0.0690\n",
      "Epoch [2/10], Step [600/3056], Loss: 0.0786\n",
      "Epoch [2/10], Step [700/3056], Loss: 0.0575\n",
      "Epoch [2/10], Step [800/3056], Loss: 0.0781\n",
      "Epoch [2/10], Step [900/3056], Loss: 0.0591\n",
      "Epoch [2/10], Step [1000/3056], Loss: 0.0687\n",
      "Epoch [2/10], Step [1100/3056], Loss: 0.0880\n",
      "Epoch [2/10], Step [1200/3056], Loss: 0.0729\n",
      "Epoch [2/10], Step [1300/3056], Loss: 0.0663\n",
      "Epoch [2/10], Step [1400/3056], Loss: 0.0310\n",
      "Epoch [2/10], Step [1500/3056], Loss: 0.0276\n",
      "Epoch [2/10], Step [1600/3056], Loss: 0.0312\n",
      "Epoch [2/10], Step [1700/3056], Loss: 0.0363\n",
      "Epoch [2/10], Step [1800/3056], Loss: 0.0325\n",
      "Epoch [2/10], Step [1900/3056], Loss: 0.0275\n",
      "Epoch [2/10], Step [2000/3056], Loss: 0.0317\n",
      "Epoch [2/10], Step [2100/3056], Loss: 0.0268\n",
      "Epoch [2/10], Step [2200/3056], Loss: 0.0264\n",
      "Epoch [2/10], Step [2300/3056], Loss: 0.0274\n",
      "Epoch [2/10], Step [2400/3056], Loss: 0.0243\n",
      "Epoch [2/10], Step [2500/3056], Loss: 0.0307\n",
      "Epoch [2/10], Step [2600/3056], Loss: 0.0300\n",
      "Epoch [2/10], Step [2700/3056], Loss: 0.0271\n",
      "Epoch [2/10], Step [2800/3056], Loss: 0.0197\n",
      "Epoch [2/10], Step [2900/3056], Loss: 0.0302\n",
      "Epoch [2/10], Step [3000/3056], Loss: 0.0171\n",
      "Epoch [3/10], Step [100/3056], Loss: 0.0263\n",
      "Epoch [3/10], Step [200/3056], Loss: 0.0285\n",
      "Epoch [3/10], Step [300/3056], Loss: 0.0193\n",
      "Epoch [3/10], Step [400/3056], Loss: 0.0230\n",
      "Epoch [3/10], Step [500/3056], Loss: 0.0153\n",
      "Epoch [3/10], Step [600/3056], Loss: 0.0269\n",
      "Epoch [3/10], Step [700/3056], Loss: 0.0315\n",
      "Epoch [3/10], Step [800/3056], Loss: 0.0147\n",
      "Epoch [3/10], Step [900/3056], Loss: 0.0179\n",
      "Epoch [3/10], Step [1000/3056], Loss: 0.0208\n",
      "Epoch [3/10], Step [1100/3056], Loss: 0.0160\n",
      "Epoch [3/10], Step [1200/3056], Loss: 0.0248\n",
      "Epoch [3/10], Step [1300/3056], Loss: 0.0249\n",
      "Epoch [3/10], Step [1400/3056], Loss: 0.0138\n",
      "Epoch [3/10], Step [1500/3056], Loss: 0.0159\n",
      "Epoch [3/10], Step [1600/3056], Loss: 0.0249\n",
      "Epoch [3/10], Step [1700/3056], Loss: 0.0119\n",
      "Epoch [3/10], Step [1800/3056], Loss: 0.0184\n",
      "Epoch [3/10], Step [1900/3056], Loss: 0.0172\n",
      "Epoch [3/10], Step [2000/3056], Loss: 0.0125\n",
      "Epoch [3/10], Step [2100/3056], Loss: 0.0134\n",
      "Epoch [3/10], Step [2200/3056], Loss: 0.0100\n",
      "Epoch [3/10], Step [2300/3056], Loss: 0.0131\n",
      "Epoch [3/10], Step [2400/3056], Loss: 0.0148\n",
      "Epoch [3/10], Step [2500/3056], Loss: 0.0168\n",
      "Epoch [3/10], Step [2600/3056], Loss: 0.0226\n",
      "Epoch [3/10], Step [2700/3056], Loss: 0.0140\n",
      "Epoch [3/10], Step [2800/3056], Loss: 0.0114\n",
      "Epoch [3/10], Step [2900/3056], Loss: 0.0155\n",
      "Epoch [3/10], Step [3000/3056], Loss: 0.0119\n",
      "Epoch [4/10], Step [100/3056], Loss: 0.0203\n",
      "Epoch [4/10], Step [200/3056], Loss: 0.0147\n",
      "Epoch [4/10], Step [300/3056], Loss: 0.0172\n",
      "Epoch [4/10], Step [400/3056], Loss: 0.0133\n",
      "Epoch [4/10], Step [500/3056], Loss: 0.0247\n",
      "Epoch [4/10], Step [600/3056], Loss: 0.0110\n",
      "Epoch [4/10], Step [700/3056], Loss: 0.0193\n",
      "Epoch [4/10], Step [800/3056], Loss: 0.0202\n",
      "Epoch [4/10], Step [900/3056], Loss: 0.0175\n",
      "Epoch [4/10], Step [1000/3056], Loss: 0.0297\n",
      "Epoch [4/10], Step [1100/3056], Loss: 0.0124\n",
      "Epoch [4/10], Step [1200/3056], Loss: 0.0171\n",
      "Epoch [4/10], Step [1300/3056], Loss: 0.0134\n",
      "Epoch [4/10], Step [1400/3056], Loss: 0.0107\n",
      "Epoch [4/10], Step [1500/3056], Loss: 0.0134\n",
      "Epoch [4/10], Step [1600/3056], Loss: 0.0146\n",
      "Epoch [4/10], Step [1700/3056], Loss: 0.0126\n",
      "Epoch [4/10], Step [1800/3056], Loss: 0.0118\n",
      "Epoch [4/10], Step [1900/3056], Loss: 0.0172\n",
      "Epoch [4/10], Step [2000/3056], Loss: 0.0085\n",
      "Epoch [4/10], Step [2100/3056], Loss: 0.0074\n",
      "Epoch [4/10], Step [2200/3056], Loss: 0.0128\n",
      "Epoch [4/10], Step [2300/3056], Loss: 0.0204\n",
      "Epoch [4/10], Step [2400/3056], Loss: 0.0104\n",
      "Epoch [4/10], Step [2500/3056], Loss: 0.0225\n",
      "Epoch [4/10], Step [2600/3056], Loss: 0.0132\n",
      "Epoch [4/10], Step [2700/3056], Loss: 0.0127\n",
      "Epoch [4/10], Step [2800/3056], Loss: 0.0151\n",
      "Epoch [4/10], Step [2900/3056], Loss: 0.0152\n",
      "Epoch [4/10], Step [3000/3056], Loss: 0.0144\n",
      "Epoch [5/10], Step [100/3056], Loss: 0.0197\n",
      "Epoch [5/10], Step [200/3056], Loss: 0.0129\n",
      "Epoch [5/10], Step [300/3056], Loss: 0.0102\n",
      "Epoch [5/10], Step [400/3056], Loss: 0.0156\n",
      "Epoch [5/10], Step [500/3056], Loss: 0.0114\n",
      "Epoch [5/10], Step [600/3056], Loss: 0.0091\n",
      "Epoch [5/10], Step [700/3056], Loss: 0.0101\n",
      "Epoch [5/10], Step [800/3056], Loss: 0.0156\n",
      "Epoch [5/10], Step [900/3056], Loss: 0.0231\n",
      "Epoch [5/10], Step [1000/3056], Loss: 0.0182\n",
      "Epoch [5/10], Step [1100/3056], Loss: 0.0151\n",
      "Epoch [5/10], Step [1200/3056], Loss: 0.0066\n",
      "Epoch [5/10], Step [1300/3056], Loss: 0.0119\n",
      "Epoch [5/10], Step [1400/3056], Loss: 0.0215\n",
      "Epoch [5/10], Step [1500/3056], Loss: 0.0131\n",
      "Epoch [5/10], Step [1600/3056], Loss: 0.0205\n",
      "Epoch [5/10], Step [1700/3056], Loss: 0.0125\n",
      "Epoch [5/10], Step [1800/3056], Loss: 0.0116\n",
      "Epoch [5/10], Step [1900/3056], Loss: 0.0206\n",
      "Epoch [5/10], Step [2000/3056], Loss: 0.0115\n",
      "Epoch [5/10], Step [2100/3056], Loss: 0.0112\n",
      "Epoch [5/10], Step [2200/3056], Loss: 0.0198\n",
      "Epoch [5/10], Step [2300/3056], Loss: 0.0301\n",
      "Epoch [5/10], Step [2400/3056], Loss: 0.0141\n",
      "Epoch [5/10], Step [2500/3056], Loss: 0.0139\n",
      "Epoch [5/10], Step [2600/3056], Loss: 0.0182\n",
      "Epoch [5/10], Step [2700/3056], Loss: 0.0189\n",
      "Epoch [5/10], Step [2800/3056], Loss: 0.0130\n",
      "Epoch [5/10], Step [2900/3056], Loss: 0.0130\n",
      "Epoch [5/10], Step [3000/3056], Loss: 0.0167\n",
      "Epoch [6/10], Step [100/3056], Loss: 0.0112\n",
      "Epoch [6/10], Step [200/3056], Loss: 0.0247\n",
      "Epoch [6/10], Step [300/3056], Loss: 0.0233\n",
      "Epoch [6/10], Step [400/3056], Loss: 0.0171\n",
      "Epoch [6/10], Step [500/3056], Loss: 0.0129\n",
      "Epoch [6/10], Step [600/3056], Loss: 0.0173\n",
      "Epoch [6/10], Step [700/3056], Loss: 0.0137\n",
      "Epoch [6/10], Step [800/3056], Loss: 0.0104\n",
      "Epoch [6/10], Step [900/3056], Loss: 0.0083\n",
      "Epoch [6/10], Step [1000/3056], Loss: 0.0103\n",
      "Epoch [6/10], Step [1100/3056], Loss: 0.0148\n",
      "Epoch [6/10], Step [1200/3056], Loss: 0.0097\n",
      "Epoch [6/10], Step [1300/3056], Loss: 0.0102\n",
      "Epoch [6/10], Step [1400/3056], Loss: 0.0149\n",
      "Epoch [6/10], Step [1500/3056], Loss: 0.0197\n",
      "Epoch [6/10], Step [1600/3056], Loss: 0.0073\n",
      "Epoch [6/10], Step [1700/3056], Loss: 0.0191\n",
      "Epoch [6/10], Step [1800/3056], Loss: 0.0172\n",
      "Epoch [6/10], Step [1900/3056], Loss: 0.0136\n",
      "Epoch [6/10], Step [2000/3056], Loss: 0.0118\n",
      "Epoch [6/10], Step [2100/3056], Loss: 0.0069\n",
      "Epoch [6/10], Step [2200/3056], Loss: 0.0132\n",
      "Epoch [6/10], Step [2300/3056], Loss: 0.0130\n",
      "Epoch [6/10], Step [2400/3056], Loss: 0.0114\n",
      "Epoch [6/10], Step [2500/3056], Loss: 0.0093\n",
      "Epoch [6/10], Step [2600/3056], Loss: 0.0108\n",
      "Epoch [6/10], Step [2700/3056], Loss: 0.0096\n",
      "Epoch [6/10], Step [2800/3056], Loss: 0.0135\n",
      "Epoch [6/10], Step [2900/3056], Loss: 0.0193\n",
      "Epoch [6/10], Step [3000/3056], Loss: 0.0156\n",
      "Epoch [7/10], Step [100/3056], Loss: 0.0167\n",
      "Epoch [7/10], Step [200/3056], Loss: 0.0062\n",
      "Epoch [7/10], Step [300/3056], Loss: 0.0134\n",
      "Epoch [7/10], Step [400/3056], Loss: 0.0116\n",
      "Epoch [7/10], Step [500/3056], Loss: 0.0179\n",
      "Epoch [7/10], Step [600/3056], Loss: 0.0091\n",
      "Epoch [7/10], Step [700/3056], Loss: 0.0146\n",
      "Epoch [7/10], Step [800/3056], Loss: 0.0149\n",
      "Epoch [7/10], Step [900/3056], Loss: 0.0216\n",
      "Epoch [7/10], Step [1000/3056], Loss: 0.0179\n",
      "Epoch [7/10], Step [1100/3056], Loss: 0.0142\n",
      "Epoch [7/10], Step [1200/3056], Loss: 0.0123\n",
      "Epoch [7/10], Step [1300/3056], Loss: 0.0109\n",
      "Epoch [7/10], Step [1400/3056], Loss: 0.0151\n",
      "Epoch [7/10], Step [1500/3056], Loss: 0.0114\n",
      "Epoch [7/10], Step [1600/3056], Loss: 0.0152\n",
      "Epoch [7/10], Step [1700/3056], Loss: 0.0140\n",
      "Epoch [7/10], Step [1800/3056], Loss: 0.0103\n",
      "Epoch [7/10], Step [1900/3056], Loss: 0.0158\n",
      "Epoch [7/10], Step [2000/3056], Loss: 0.0093\n",
      "Epoch [7/10], Step [2100/3056], Loss: 0.0201\n",
      "Epoch [7/10], Step [2200/3056], Loss: 0.0179\n",
      "Epoch [7/10], Step [2300/3056], Loss: 0.0096\n",
      "Epoch [7/10], Step [2400/3056], Loss: 0.0121\n",
      "Epoch [7/10], Step [2500/3056], Loss: 0.0089\n",
      "Epoch [7/10], Step [2600/3056], Loss: 0.0206\n",
      "Epoch [7/10], Step [2700/3056], Loss: 0.0174\n",
      "Epoch [7/10], Step [2800/3056], Loss: 0.0155\n",
      "Epoch [7/10], Step [2900/3056], Loss: 0.0205\n",
      "Epoch [7/10], Step [3000/3056], Loss: 0.0101\n",
      "Epoch [8/10], Step [100/3056], Loss: 0.0102\n",
      "Epoch [8/10], Step [200/3056], Loss: 0.0126\n",
      "Epoch [8/10], Step [300/3056], Loss: 0.0229\n",
      "Epoch [8/10], Step [400/3056], Loss: 0.0200\n",
      "Epoch [8/10], Step [500/3056], Loss: 0.0159\n",
      "Epoch [8/10], Step [600/3056], Loss: 0.0067\n",
      "Epoch [8/10], Step [700/3056], Loss: 0.0204\n",
      "Epoch [8/10], Step [800/3056], Loss: 0.0089\n",
      "Epoch [8/10], Step [900/3056], Loss: 0.0176\n",
      "Epoch [8/10], Step [1000/3056], Loss: 0.0188\n",
      "Epoch [8/10], Step [1100/3056], Loss: 0.0102\n",
      "Epoch [8/10], Step [1200/3056], Loss: 0.0124\n",
      "Epoch [8/10], Step [1300/3056], Loss: 0.0104\n",
      "Epoch [8/10], Step [1400/3056], Loss: 0.0139\n",
      "Epoch [8/10], Step [1500/3056], Loss: 0.0150\n",
      "Epoch [8/10], Step [1600/3056], Loss: 0.0135\n",
      "Epoch [8/10], Step [1700/3056], Loss: 0.0111\n",
      "Epoch [8/10], Step [1800/3056], Loss: 0.0170\n",
      "Epoch [8/10], Step [1900/3056], Loss: 0.0227\n",
      "Epoch [8/10], Step [2000/3056], Loss: 0.0106\n",
      "Epoch [8/10], Step [2100/3056], Loss: 0.0213\n",
      "Epoch [8/10], Step [2200/3056], Loss: 0.0150\n",
      "Epoch [8/10], Step [2300/3056], Loss: 0.0119\n",
      "Epoch [8/10], Step [2400/3056], Loss: 0.0129\n",
      "Epoch [8/10], Step [2500/3056], Loss: 0.0156\n",
      "Epoch [8/10], Step [2600/3056], Loss: 0.0163\n",
      "Epoch [8/10], Step [2700/3056], Loss: 0.0209\n",
      "Epoch [8/10], Step [2800/3056], Loss: 0.0236\n",
      "Epoch [8/10], Step [2900/3056], Loss: 0.0078\n",
      "Epoch [8/10], Step [3000/3056], Loss: 0.0105\n",
      "Epoch [9/10], Step [100/3056], Loss: 0.0150\n",
      "Epoch [9/10], Step [200/3056], Loss: 0.0127\n",
      "Epoch [9/10], Step [300/3056], Loss: 0.0142\n",
      "Epoch [9/10], Step [400/3056], Loss: 0.0150\n",
      "Epoch [9/10], Step [500/3056], Loss: 0.0115\n",
      "Epoch [9/10], Step [600/3056], Loss: 0.0153\n",
      "Epoch [9/10], Step [700/3056], Loss: 0.0349\n",
      "Epoch [9/10], Step [800/3056], Loss: 0.0306\n",
      "Epoch [9/10], Step [900/3056], Loss: 0.0122\n",
      "Epoch [9/10], Step [1000/3056], Loss: 0.0195\n",
      "Epoch [9/10], Step [1100/3056], Loss: 0.0108\n",
      "Epoch [9/10], Step [1200/3056], Loss: 0.0087\n",
      "Epoch [9/10], Step [1300/3056], Loss: 0.0193\n",
      "Epoch [9/10], Step [1400/3056], Loss: 0.0185\n",
      "Epoch [9/10], Step [1500/3056], Loss: 0.0074\n",
      "Epoch [9/10], Step [1600/3056], Loss: 0.0131\n",
      "Epoch [9/10], Step [1700/3056], Loss: 0.0096\n",
      "Epoch [9/10], Step [1800/3056], Loss: 0.0084\n",
      "Epoch [9/10], Step [1900/3056], Loss: 0.0173\n",
      "Epoch [9/10], Step [2000/3056], Loss: 0.0162\n",
      "Epoch [9/10], Step [2100/3056], Loss: 0.0100\n",
      "Epoch [9/10], Step [2200/3056], Loss: 0.0139\n",
      "Epoch [9/10], Step [2300/3056], Loss: 0.0127\n",
      "Epoch [9/10], Step [2400/3056], Loss: 0.0123\n",
      "Epoch [9/10], Step [2500/3056], Loss: 0.0105\n",
      "Epoch [9/10], Step [2600/3056], Loss: 0.0084\n",
      "Epoch [9/10], Step [2700/3056], Loss: 0.0156\n",
      "Epoch [9/10], Step [2800/3056], Loss: 0.0113\n",
      "Epoch [9/10], Step [2900/3056], Loss: 0.0189\n",
      "Epoch [9/10], Step [3000/3056], Loss: 0.0088\n",
      "Epoch [10/10], Step [100/3056], Loss: 0.0113\n",
      "Epoch [10/10], Step [200/3056], Loss: 0.0175\n",
      "Epoch [10/10], Step [300/3056], Loss: 0.0147\n",
      "Epoch [10/10], Step [400/3056], Loss: 0.0209\n",
      "Epoch [10/10], Step [500/3056], Loss: 0.0179\n",
      "Epoch [10/10], Step [600/3056], Loss: 0.0116\n",
      "Epoch [10/10], Step [700/3056], Loss: 0.0084\n",
      "Epoch [10/10], Step [800/3056], Loss: 0.0099\n",
      "Epoch [10/10], Step [900/3056], Loss: 0.0120\n",
      "Epoch [10/10], Step [1000/3056], Loss: 0.0136\n",
      "Epoch [10/10], Step [1100/3056], Loss: 0.0117\n",
      "Epoch [10/10], Step [1200/3056], Loss: 0.0109\n",
      "Epoch [10/10], Step [1300/3056], Loss: 0.0161\n",
      "Epoch [10/10], Step [1400/3056], Loss: 0.0174\n",
      "Epoch [10/10], Step [1500/3056], Loss: 0.0149\n",
      "Epoch [10/10], Step [1600/3056], Loss: 0.0136\n",
      "Epoch [10/10], Step [1700/3056], Loss: 0.0149\n",
      "Epoch [10/10], Step [1800/3056], Loss: 0.0101\n",
      "Epoch [10/10], Step [1900/3056], Loss: 0.0058\n",
      "Epoch [10/10], Step [2000/3056], Loss: 0.0261\n",
      "Epoch [10/10], Step [2100/3056], Loss: 0.0128\n",
      "Epoch [10/10], Step [2200/3056], Loss: 0.0132\n",
      "Epoch [10/10], Step [2300/3056], Loss: 0.0217\n",
      "Epoch [10/10], Step [2400/3056], Loss: 0.0157\n",
      "Epoch [10/10], Step [2500/3056], Loss: 0.0120\n",
      "Epoch [10/10], Step [2600/3056], Loss: 0.0085\n",
      "Epoch [10/10], Step [2700/3056], Loss: 0.0113\n",
      "Epoch [10/10], Step [2800/3056], Loss: 0.0212\n",
      "Epoch [10/10], Step [2900/3056], Loss: 0.0215\n",
      "Epoch [10/10], Step [3000/3056], Loss: 0.0169\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'original_img_data_path': 'data\\\\image\\\\',\n",
    "    'hazy_img_data_path': 'data\\\\data\\\\',\n",
    "    'model_path': '.\\\\model\\\\',\n",
    "    'output_path': '.\\\\output\\\\',\n",
    "    'num_epochs': 10,\n",
    "    'batch_size': 8,\n",
    "    'learning_rate': 0.0001,\n",
    "    'weight_decay': 0.0001,\n",
    "    'grad_clip_norm': 0.1,\n",
    "    'display_iter': 100,\n",
    "    'save_iter': 100\n",
    "}\n",
    "if not os.path.exists(config['model_path']):\n",
    "    os.makedirs(config['model_path'])\n",
    "if not os.path.exists(config['output_path']):\n",
    "    os.makedirs(config['output_path'])\n",
    "train(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'original_img_data_path': 'data\\\\image\\\\',\n",
    "    'hazy_img_data_path': 'data\\\\data\\\\',\n",
    "    'model_path': '.\\\\model\\\\',\n",
    "    'output_path': '.\\\\output\\\\',\n",
    "    'num_epochs': 10,\n",
    "    'batch_size': 8,\n",
    "    'learning_rate': 0.0001,\n",
    "    'weight_decay': 0.0001,\n",
    "    'grad_clip_norm': 0.1,\n",
    "    'display_iter': 100,\n",
    "    'save_iter': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AODNet()\n",
    "model.load_state_dict(torch.load('./model/model-10.ckpt'), strict=False)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "val_dataset = create_dataloader(config['original_img_data_path'], config['hazy_img_data_path'], mode=\"val\")\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "for i, (org_img, hazy_img) in enumerate(val_loader):\n",
    "        org_img = org_img.to(device)\n",
    "        hazy_img = hazy_img.to(device)\n",
    "        with torch.no_grad():\n",
    "                clean_img = model(hazy_img)\n",
    "        loss = loss_fn(clean_img, org_img)\n",
    "        torchvision.utils.save_image(torch.cat((hazy_img, clean_img, org_img),0), \"./output/\" + 'clean_img_{}.jpg'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For NH-Haze Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul chauhan\\AppData\\Local\\Temp\\ipykernel_37400\\3880783649.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('./model/model-10.ckpt'), strict=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1: PSNR = 14.69, SSIM = 0.1861\n",
      "Image 2: PSNR = 14.38, SSIM = 0.4413\n",
      "Image 3: PSNR = 11.20, SSIM = 0.3630\n",
      "Image 4: PSNR = 10.80, SSIM = 0.5842\n",
      "Image 5: PSNR = 12.39, SSIM = 0.4228\n",
      "Saved batch 1 visualization to outputs\\batch_1.png\n",
      "Image 6: PSNR = 9.82, SSIM = 0.1767\n",
      "Image 7: PSNR = 10.13, SSIM = 0.1963\n",
      "Image 8: PSNR = 10.63, SSIM = 0.3962\n",
      "Image 9: PSNR = 9.81, SSIM = 0.2107\n",
      "Image 10: PSNR = 12.82, SSIM = 0.2301\n",
      "Saved batch 2 visualization to outputs\\batch_2.png\n",
      "Image 11: PSNR = 13.24, SSIM = -0.1122\n",
      "Image 12: PSNR = 13.15, SSIM = -0.0012\n",
      "Image 13: PSNR = 11.67, SSIM = 0.2360\n",
      "Image 14: PSNR = 10.77, SSIM = 0.3951\n",
      "Image 15: PSNR = 15.07, SSIM = 0.5516\n",
      "Saved batch 3 visualization to outputs\\batch_3.png\n",
      "Image 16: PSNR = 12.43, SSIM = 0.5196\n",
      "Image 17: PSNR = 13.54, SSIM = 0.1181\n",
      "Image 18: PSNR = 13.02, SSIM = 0.2327\n",
      "Image 19: PSNR = 12.71, SSIM = 0.0356\n",
      "Image 20: PSNR = 12.13, SSIM = -0.0980\n",
      "Saved batch 4 visualization to outputs\\batch_4.png\n",
      "Image 21: PSNR = 11.50, SSIM = 0.1708\n",
      "Image 22: PSNR = 12.16, SSIM = -0.1271\n",
      "Image 23: PSNR = 12.20, SSIM = 0.4095\n",
      "Image 24: PSNR = 13.29, SSIM = 0.3385\n",
      "Image 25: PSNR = 14.93, SSIM = -0.0036\n",
      "Saved batch 5 visualization to outputs\\batch_5.png\n",
      "Image 26: PSNR = 11.40, SSIM = -0.0417\n",
      "Image 27: PSNR = 11.57, SSIM = -0.1081\n",
      "Image 28: PSNR = 8.79, SSIM = 0.1848\n",
      "Image 29: PSNR = 11.20, SSIM = 0.0402\n",
      "Image 30: PSNR = 9.34, SSIM = 0.2396\n",
      "Saved batch 6 visualization to outputs\\batch_6.png\n",
      "Image 31: PSNR = 9.77, SSIM = 0.1658\n",
      "Image 32: PSNR = 13.81, SSIM = 0.2810\n",
      "Image 33: PSNR = 13.66, SSIM = 0.2411\n",
      "Image 34: PSNR = 15.05, SSIM = 0.2576\n",
      "Image 35: PSNR = 14.09, SSIM = 0.4499\n",
      "Saved batch 7 visualization to outputs\\batch_7.png\n",
      "Image 36: PSNR = 13.31, SSIM = 0.2495\n",
      "Image 37: PSNR = 11.93, SSIM = 0.4420\n",
      "Image 38: PSNR = 14.12, SSIM = 0.3292\n",
      "Image 39: PSNR = 11.56, SSIM = 0.3164\n",
      "Image 40: PSNR = 12.19, SSIM = 0.6505\n",
      "Saved batch 8 visualization to outputs\\batch_8.png\n",
      "Image 41: PSNR = 11.46, SSIM = 0.5315\n",
      "Image 42: PSNR = 13.23, SSIM = 0.2974\n",
      "Image 43: PSNR = 10.44, SSIM = 0.2168\n",
      "Image 44: PSNR = 9.71, SSIM = 0.3085\n",
      "Image 45: PSNR = 13.53, SSIM = 0.2851\n",
      "Saved batch 9 visualization to outputs\\batch_9.png\n",
      "Image 46: PSNR = 10.17, SSIM = 0.1915\n",
      "Image 47: PSNR = 8.97, SSIM = 0.4170\n",
      "Image 48: PSNR = 11.43, SSIM = -0.0597\n",
      "Image 49: PSNR = 13.96, SSIM = 0.1111\n",
      "Image 50: PSNR = 11.87, SSIM = 0.2770\n",
      "Saved batch 10 visualization to outputs\\batch_10.png\n",
      "Image 51: PSNR = 15.55, SSIM = 0.4636\n",
      "Image 52: PSNR = 12.61, SSIM = 0.0531\n",
      "Image 53: PSNR = 12.08, SSIM = 0.0502\n",
      "Image 54: PSNR = 12.48, SSIM = 0.1898\n",
      "Image 55: PSNR = 11.59, SSIM = 0.1780\n",
      "Saved batch 11 visualization to outputs\\batch_11.png\n",
      "Average PSNR: 12.17\n",
      "Average SSIM: 0.2378\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim \n",
    "\n",
    "# Custom Dataset\n",
    "class create_dataloader_output(Dataset):\n",
    "    def __init__(self, img_folder, mode=\"train\"):\n",
    "        # Create lists of hazy and ground truth images dynamically\n",
    "        self.hazy_images = [os.path.join(img_folder, f) for f in os.listdir(img_folder) if not f.endswith('_GT.png')]\n",
    "        self.gt_images = [os.path.join(img_folder, f) for f in os.listdir(img_folder) if f.endswith('_GT.png')]\n",
    "\n",
    "        # Match hazy images with their corresponding ground truth\n",
    "        self.data_list = []\n",
    "        for hazy_img in self.hazy_images:\n",
    "            gt_img = hazy_img.replace('_hazy.png', '_GT.png')  # Assuming same name with _GT\n",
    "            if gt_img in self.gt_images:\n",
    "                self.data_list.append((hazy_img, gt_img))\n",
    "\n",
    "        print(f'Total images: {len(self.data_list)}')\n",
    "\n",
    "    def transform(self, img):\n",
    "        np_array = np.asarray(img.resize((480, 640), Image.BILINEAR)).copy()\n",
    "        return torch.from_numpy(np_array).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hazy_img_path, gt_img_path = self.data_list[idx]\n",
    "        hazy_img = Image.open(hazy_img_path).convert(\"RGB\")\n",
    "        gt_img = Image.open(gt_img_path).convert(\"RGB\")\n",
    "        hazy_img = self.transform(hazy_img)\n",
    "        gt_img = self.transform(gt_img)\n",
    "        return hazy_img, gt_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "\n",
    "# Path to images\n",
    "img_folder = \"./NH-HAZE\"\n",
    "output_dir = \"outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "dataset = create_dataloader_output(img_folder)\n",
    "data_loader = DataLoader(dataset, batch_size=5, shuffle=False)\n",
    "\n",
    "# Assuming a pre-trained dehazing model is loaded\n",
    "class DehazingModel(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * 0.9  # Dummy dehazing; replace with actual model logic\n",
    "\n",
    "model = AODNet()\n",
    "# weights_path = \"./model/model-10.ckpt\"  # Update with the correct path\n",
    "model.load_state_dict(torch.load('./model/model-10.ckpt'), strict=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "total_psnr = 0\n",
    "total_ssim = 0\n",
    "num_images = 0\n",
    "\n",
    "# Process and Save Batches\n",
    "for idx, (hazy_imgs, gt_imgs) in enumerate(data_loader):\n",
    "    with torch.no_grad():\n",
    "        hazy_imgs = hazy_imgs.to(device)\n",
    "        dehazed_imgs = model(hazy_imgs)  # Dehaze the hazy images\n",
    "\n",
    "    \n",
    "\n",
    "    # Plot and Save Results\n",
    "    fig, axs = plt.subplots(5, 3, figsize=(7, 15))\n",
    "    axs[0, 0].set_title(\"Hazy Image\")\n",
    "    axs[0, 1].set_title(\"Dehazed Image\")\n",
    "    axs[0, 2].set_title(\"Ground Truth\")\n",
    "    for i in range(len(hazy_imgs)):\n",
    "        hazy_img_np = hazy_imgs[i].cpu().permute(1, 2, 0).numpy()\n",
    "        dehazed_img_np = dehazed_imgs[i].cpu().permute(1, 2, 0).numpy()\n",
    "        gt_img_np = gt_imgs[i].cpu().permute(1, 2, 0).numpy()\n",
    "        hazy_img_np = np.clip(hazy_img_np, 0, 1)\n",
    "        dehazed_img_np = np.clip(dehazed_img_np, 0, 1)\n",
    "        gt_img_np = np.clip(gt_img_np, 0, 1)\n",
    "        psnr_value = psnr(gt_img_np, dehazed_img_np, data_range=1.0)  # data_range=1.0 for normalized images\n",
    "        ssim_value = ssim(gt_img_np, dehazed_img_np, multichannel=True, data_range=1.0, win_size=3)\n",
    "        # Accumulate metrics\n",
    "        total_psnr += psnr_value\n",
    "        total_ssim += ssim_value\n",
    "        num_images += 1\n",
    "        axs[i, 0].imshow(hazy_img_np)\n",
    "        axs[i, 1].imshow(dehazed_img_np)\n",
    "        axs[i, 2].imshow(gt_img_np)\n",
    "        axs[i, 0].axis(\"off\")\n",
    "        axs[i, 1].axis(\"off\")\n",
    "        axs[i, 2].axis(\"off\")\n",
    "        print(f\"Image {num_images}: PSNR = {psnr_value:.2f}, SSIM = {ssim_value:.4f}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the visualization to the outputs folder\n",
    "    save_path = os.path.join(output_dir, f\"batch_{idx + 1}.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Saved batch {idx + 1} visualization to {save_path}\")\n",
    "\n",
    "\n",
    "# Calculate averages\n",
    "average_psnr = total_psnr / num_images\n",
    "average_ssim = total_ssim / num_images\n",
    "\n",
    "# Print final results\n",
    "print(f\"Average PSNR: {average_psnr:.2f}\")\n",
    "print(f\"Average SSIM: {average_ssim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For SOTs Indoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul chauhan\\AppData\\Local\\Temp\\ipykernel_37400\\4286031947.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weights_path, map_location=device), strict=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1: PSNR = 17.17, SSIM = 0.8234\n",
      "Image 2: PSNR = 20.16, SSIM = 0.8224\n",
      "Image 3: PSNR = 20.55, SSIM = 0.8014\n",
      "Image 4: PSNR = 17.35, SSIM = 0.7251\n",
      "Image 5: PSNR = 21.31, SSIM = 0.9063\n",
      "Saved batch 1 visualization to outputs_SOT\\batch_1.png\n",
      "Image 6: PSNR = 20.67, SSIM = 0.9095\n",
      "Image 7: PSNR = 21.16, SSIM = 0.9071\n",
      "Image 8: PSNR = 20.88, SSIM = 0.9226\n",
      "Image 9: PSNR = 20.26, SSIM = 0.9265\n",
      "Image 10: PSNR = 21.19, SSIM = 0.9205\n",
      "Saved batch 2 visualization to outputs_SOT\\batch_2.png\n",
      "Image 11: PSNR = 19.81, SSIM = 0.9053\n",
      "Image 12: PSNR = 17.66, SSIM = 0.8059\n",
      "Image 13: PSNR = 18.74, SSIM = 0.8503\n",
      "Image 14: PSNR = 14.84, SSIM = 0.8101\n",
      "Image 15: PSNR = 17.38, SSIM = 0.8418\n",
      "Saved batch 3 visualization to outputs_SOT\\batch_3.png\n",
      "Image 16: PSNR = 20.90, SSIM = 0.8902\n",
      "Image 17: PSNR = 18.30, SSIM = 0.8921\n",
      "Image 18: PSNR = 19.68, SSIM = 0.9087\n",
      "Image 19: PSNR = 20.53, SSIM = 0.8966\n",
      "Image 20: PSNR = 19.97, SSIM = 0.9019\n",
      "Saved batch 4 visualization to outputs_SOT\\batch_4.png\n",
      "Image 21: PSNR = 15.31, SSIM = 0.8077\n",
      "Image 22: PSNR = 20.80, SSIM = 0.8754\n",
      "Image 23: PSNR = 18.53, SSIM = 0.7351\n",
      "Image 24: PSNR = 15.47, SSIM = 0.6842\n",
      "Image 25: PSNR = 19.18, SSIM = 0.8502\n",
      "Saved batch 5 visualization to outputs_SOT\\batch_5.png\n",
      "Image 26: PSNR = 14.80, SSIM = 0.7531\n",
      "Image 27: PSNR = 17.53, SSIM = 0.7613\n",
      "Image 28: PSNR = 19.78, SSIM = 0.8264\n",
      "Image 29: PSNR = 17.39, SSIM = 0.7865\n",
      "Image 30: PSNR = 14.41, SSIM = 0.6786\n",
      "Saved batch 6 visualization to outputs_SOT\\batch_6.png\n",
      "Image 31: PSNR = 17.89, SSIM = 0.6231\n",
      "Image 32: PSNR = 17.38, SSIM = 0.7359\n",
      "Image 33: PSNR = 21.47, SSIM = 0.8075\n",
      "Image 34: PSNR = 20.98, SSIM = 0.8268\n",
      "Image 35: PSNR = 20.39, SSIM = 0.8897\n",
      "Saved batch 7 visualization to outputs_SOT\\batch_7.png\n",
      "Image 36: PSNR = 18.46, SSIM = 0.8647\n",
      "Image 37: PSNR = 24.01, SSIM = 0.9312\n",
      "Image 38: PSNR = 17.22, SSIM = 0.8201\n",
      "Image 39: PSNR = 19.18, SSIM = 0.8046\n",
      "Image 40: PSNR = 20.03, SSIM = 0.9068\n",
      "Saved batch 8 visualization to outputs_SOT\\batch_8.png\n",
      "Image 41: PSNR = 15.25, SSIM = 0.8344\n",
      "Image 42: PSNR = 21.00, SSIM = 0.8594\n",
      "Image 43: PSNR = 16.70, SSIM = 0.7848\n",
      "Image 44: PSNR = 21.43, SSIM = 0.8598\n",
      "Image 45: PSNR = 16.61, SSIM = 0.7024\n",
      "Saved batch 9 visualization to outputs_SOT\\batch_9.png\n",
      "Image 46: PSNR = 20.09, SSIM = 0.8753\n",
      "Image 47: PSNR = 19.21, SSIM = 0.8527\n",
      "Image 48: PSNR = 20.08, SSIM = 0.8767\n",
      "Image 49: PSNR = 20.17, SSIM = 0.8881\n",
      "Image 50: PSNR = 20.18, SSIM = 0.8949\n",
      "Saved batch 10 visualization to outputs_SOT\\batch_10.png\n",
      "Average PSNR: 18.99\n",
      "Average SSIM: 0.8353\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim \n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset Class\n",
    "class PairedImageDataset(Dataset):\n",
    "    def __init__(self, root_folder, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_folder (str): Path to the dataset folder containing 'clear' and 'hazy' subfolders.\n",
    "            transform (callable, optional): Transform to apply to the images.\n",
    "        \"\"\"\n",
    "        self.clear_folder = os.path.join(root_folder, \"clear\")\n",
    "        self.hazy_folder = os.path.join(root_folder, \"hazy\")\n",
    "        \n",
    "        self.hazy_images = sorted([f for f in os.listdir(self.hazy_folder) if f.endswith('_5.png')])\n",
    "        self.clear_images = [f.replace('_5', '') for f in self.hazy_images]\n",
    "        \n",
    "        for clear_img in self.clear_images:\n",
    "            if not os.path.exists(os.path.join(self.clear_folder, clear_img)):\n",
    "                raise FileNotFoundError(f\"Missing clear image: {clear_img}\")\n",
    "        \n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((256, 256)),  \n",
    "                transforms.ToTensor(),        \n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hazy_path = os.path.join(self.hazy_folder, self.hazy_images[idx])\n",
    "        clear_path = os.path.join(self.clear_folder, self.clear_images[idx])\n",
    "        \n",
    "        hazy_img = Image.open(hazy_path).convert(\"RGB\")\n",
    "        clear_img = Image.open(clear_path).convert(\"RGB\")\n",
    "        \n",
    "        hazy_img = self.transform(hazy_img)\n",
    "        clear_img = self.transform(clear_img)\n",
    "        \n",
    "        return hazy_img, clear_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hazy_images)\n",
    "\n",
    "# Dehazing Model (Dummy Example)\n",
    "class DehazingModel(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * 0.9  \n",
    "\n",
    "# Path setup\n",
    "root_folder = \"./indoor\"  \n",
    "output_dir = \"outputs_SOT\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize dataset and dataloader\n",
    "dataset = PairedImageDataset(root_folder)\n",
    "data_loader = DataLoader(dataset, batch_size=5, shuffle=False)\n",
    "\n",
    "# Load Model\n",
    "model = AODNet()  \n",
    "weights_path = \"./model/model-10.ckpt\"\n",
    "model.load_state_dict(torch.load(weights_path, map_location=device), strict=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Metrics Initialization\n",
    "total_psnr = 0\n",
    "total_ssim = 0\n",
    "num_images = 0\n",
    "\n",
    "# Process and Evaluate\n",
    "for idx, (hazy_imgs, clear_imgs) in enumerate(data_loader):\n",
    "    hazy_imgs = hazy_imgs.to(device)\n",
    "    clear_imgs = clear_imgs.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dehazed_imgs = model(hazy_imgs)\n",
    "\n",
    "    # Visualization and Metrics Calculation\n",
    "    fig, axs = plt.subplots(5, 3, figsize=(8, 13))\n",
    "    axs[0, 0].set_title(\"Hazy Image\")\n",
    "    axs[0, 1].set_title(\"Dehazed Image\")\n",
    "    axs[0, 2].set_title(\"Clear Image\")\n",
    "\n",
    "    for i in range(len(hazy_imgs)):\n",
    "        # Convert tensors to numpy for visualization and metrics\n",
    "        hazy_img_np = hazy_imgs[i].cpu().permute(1, 2, 0).numpy()\n",
    "        dehazed_img_np = dehazed_imgs[i].cpu().permute(1, 2, 0).numpy()\n",
    "        clear_img_np = clear_imgs[i].cpu().permute(1, 2, 0).numpy()\n",
    "\n",
    "        # Clip values to valid range\n",
    "        hazy_img_np = np.clip(hazy_img_np, 0, 1)\n",
    "        dehazed_img_np = np.clip(dehazed_img_np, 0, 1)\n",
    "        clear_img_np = np.clip(clear_img_np, 0, 1)\n",
    "\n",
    "        # Compute PSNR and SSIM\n",
    "        psnr_value = psnr(clear_img_np, dehazed_img_np, data_range=1.0)\n",
    "        ssim_value = ssim(clear_img_np, dehazed_img_np, channel_axis=-1, data_range=1.0)\n",
    "\n",
    "        total_psnr += psnr_value\n",
    "        total_ssim += ssim_value\n",
    "        num_images += 1\n",
    "\n",
    "        # Plot images\n",
    "        axs[i, 0].imshow(hazy_img_np)\n",
    "        axs[i, 1].imshow(dehazed_img_np)\n",
    "        axs[i, 2].imshow(clear_img_np)\n",
    "        axs[i, 0].axis(\"off\")\n",
    "        axs[i, 1].axis(\"off\")\n",
    "        axs[i, 2].axis(\"off\")\n",
    "\n",
    "        print(f\"Image {num_images}: PSNR = {psnr_value:.2f}, SSIM = {ssim_value:.4f}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save visualization\n",
    "    save_path = os.path.join(output_dir, f\"batch_{idx + 1}.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Saved batch {idx + 1} visualization to {save_path}\")\n",
    "\n",
    "# Final Metrics\n",
    "average_psnr = total_psnr / num_images\n",
    "average_ssim = total_ssim / num_images\n",
    "print(f\"Average PSNR: {average_psnr:.2f}\")\n",
    "print(f\"Average SSIM: {average_ssim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For SOTs outdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul chauhan\\AppData\\Local\\Temp\\ipykernel_37400\\2540859786.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weights_path, map_location=device), strict=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1: PSNR = 17.85, SSIM = 0.9175\n",
      "Image 2: PSNR = 16.86, SSIM = 0.8215\n",
      "Image 3: PSNR = 16.64, SSIM = 0.8915\n",
      "Image 4: PSNR = 17.98, SSIM = 0.9389\n",
      "Image 5: PSNR = 17.72, SSIM = 0.8617\n",
      "Saved batch 1 visualization to outputs_SOT_2\\batch_1.png\n",
      "Image 6: PSNR = 22.07, SSIM = 0.9104\n",
      "Image 7: PSNR = 18.95, SSIM = 0.8773\n",
      "Image 8: PSNR = 17.56, SSIM = 0.8086\n",
      "Image 9: PSNR = 21.14, SSIM = 0.8718\n",
      "Image 10: PSNR = 19.00, SSIM = 0.9243\n",
      "Saved batch 2 visualization to outputs_SOT_2\\batch_2.png\n",
      "Image 11: PSNR = 15.39, SSIM = 0.8298\n",
      "Image 12: PSNR = 19.30, SSIM = 0.9122\n",
      "Image 13: PSNR = 20.90, SSIM = 0.9266\n",
      "Image 14: PSNR = 18.91, SSIM = 0.9152\n",
      "Image 15: PSNR = 17.22, SSIM = 0.9018\n",
      "Saved batch 3 visualization to outputs_SOT_2\\batch_3.png\n",
      "Image 16: PSNR = 17.01, SSIM = 0.8682\n",
      "Image 17: PSNR = 20.95, SSIM = 0.9166\n",
      "Image 18: PSNR = 20.00, SSIM = 0.8627\n",
      "Image 19: PSNR = 18.85, SSIM = 0.9001\n",
      "Image 20: PSNR = 20.61, SSIM = 0.8824\n",
      "Saved batch 4 visualization to outputs_SOT_2\\batch_4.png\n",
      "Image 21: PSNR = 17.72, SSIM = 0.8756\n",
      "Image 22: PSNR = 22.96, SSIM = 0.9477\n",
      "Image 23: PSNR = 15.49, SSIM = 0.8365\n",
      "Image 24: PSNR = 21.40, SSIM = 0.9271\n",
      "Image 25: PSNR = 19.48, SSIM = 0.9143\n",
      "Saved batch 5 visualization to outputs_SOT_2\\batch_5.png\n",
      "Image 26: PSNR = 20.89, SSIM = 0.9126\n",
      "Image 27: PSNR = 20.73, SSIM = 0.9228\n",
      "Image 28: PSNR = 18.51, SSIM = 0.9157\n",
      "Image 29: PSNR = 17.36, SSIM = 0.9174\n",
      "Image 30: PSNR = 21.01, SSIM = 0.9083\n",
      "Saved batch 6 visualization to outputs_SOT_2\\batch_6.png\n",
      "Image 31: PSNR = 21.39, SSIM = 0.9115\n",
      "Image 32: PSNR = 18.73, SSIM = 0.8873\n",
      "Image 33: PSNR = 17.99, SSIM = 0.9001\n",
      "Image 34: PSNR = 19.65, SSIM = 0.9311\n",
      "Image 35: PSNR = 23.46, SSIM = 0.9394\n",
      "Saved batch 7 visualization to outputs_SOT_2\\batch_7.png\n",
      "Image 36: PSNR = 20.96, SSIM = 0.8998\n",
      "Image 37: PSNR = 21.19, SSIM = 0.9038\n",
      "Image 38: PSNR = 20.87, SSIM = 0.9379\n",
      "Image 39: PSNR = 18.23, SSIM = 0.8942\n",
      "Image 40: PSNR = 18.92, SSIM = 0.9207\n",
      "Saved batch 8 visualization to outputs_SOT_2\\batch_8.png\n",
      "Image 41: PSNR = 15.63, SSIM = 0.9044\n",
      "Image 42: PSNR = 19.85, SSIM = 0.9029\n",
      "Image 43: PSNR = 20.49, SSIM = 0.9331\n",
      "Image 44: PSNR = 19.53, SSIM = 0.8516\n",
      "Image 45: PSNR = 18.54, SSIM = 0.9059\n",
      "Saved batch 9 visualization to outputs_SOT_2\\batch_9.png\n",
      "Image 46: PSNR = 16.75, SSIM = 0.8407\n",
      "Image 47: PSNR = 18.53, SSIM = 0.8823\n",
      "Image 48: PSNR = 18.91, SSIM = 0.8903\n",
      "Image 49: PSNR = 20.89, SSIM = 0.9171\n",
      "Image 50: PSNR = 17.34, SSIM = 0.8999\n",
      "Saved batch 10 visualization to outputs_SOT_2\\batch_10.png\n",
      "Image 51: PSNR = 21.35, SSIM = 0.9259\n",
      "Image 52: PSNR = 22.91, SSIM = 0.9548\n",
      "Image 53: PSNR = 17.26, SSIM = 0.9016\n",
      "Image 54: PSNR = 18.60, SSIM = 0.9261\n",
      "Image 55: PSNR = 21.57, SSIM = 0.9130\n",
      "Saved batch 11 visualization to outputs_SOT_2\\batch_11.png\n",
      "Image 56: PSNR = 18.05, SSIM = 0.7890\n",
      "Image 57: PSNR = 16.02, SSIM = 0.7371\n",
      "Image 58: PSNR = 18.59, SSIM = 0.9090\n",
      "Image 59: PSNR = 20.07, SSIM = 0.9173\n",
      "Image 60: PSNR = 23.29, SSIM = 0.9423\n",
      "Saved batch 12 visualization to outputs_SOT_2\\batch_12.png\n",
      "Image 61: PSNR = 15.83, SSIM = 0.7694\n",
      "Image 62: PSNR = 18.82, SSIM = 0.9081\n",
      "Image 63: PSNR = 18.19, SSIM = 0.9422\n",
      "Image 64: PSNR = 19.54, SSIM = 0.9247\n",
      "Image 65: PSNR = 18.31, SSIM = 0.9140\n",
      "Saved batch 13 visualization to outputs_SOT_2\\batch_13.png\n",
      "Image 66: PSNR = 23.90, SSIM = 0.9348\n",
      "Image 67: PSNR = 20.13, SSIM = 0.8270\n",
      "Image 68: PSNR = 19.51, SSIM = 0.8984\n",
      "Image 69: PSNR = 22.57, SSIM = 0.9305\n",
      "Image 70: PSNR = 20.82, SSIM = 0.9300\n",
      "Saved batch 14 visualization to outputs_SOT_2\\batch_14.png\n",
      "Image 71: PSNR = 22.29, SSIM = 0.9310\n",
      "Image 72: PSNR = 19.61, SSIM = 0.9038\n",
      "Image 73: PSNR = 18.94, SSIM = 0.9315\n",
      "Image 74: PSNR = 21.22, SSIM = 0.9387\n",
      "Image 75: PSNR = 20.95, SSIM = 0.9322\n",
      "Saved batch 15 visualization to outputs_SOT_2\\batch_15.png\n",
      "Image 76: PSNR = 15.76, SSIM = 0.8710\n",
      "Image 77: PSNR = 17.22, SSIM = 0.8860\n",
      "Image 78: PSNR = 17.82, SSIM = 0.8915\n",
      "Image 79: PSNR = 19.51, SSIM = 0.9386\n",
      "Image 80: PSNR = 16.52, SSIM = 0.8932\n",
      "Saved batch 16 visualization to outputs_SOT_2\\batch_16.png\n",
      "Image 81: PSNR = 19.30, SSIM = 0.8975\n",
      "Image 82: PSNR = 21.96, SSIM = 0.9276\n",
      "Image 83: PSNR = 21.10, SSIM = 0.9359\n",
      "Image 84: PSNR = 17.52, SSIM = 0.8135\n",
      "Image 85: PSNR = 18.02, SSIM = 0.9049\n",
      "Saved batch 17 visualization to outputs_SOT_2\\batch_17.png\n",
      "Image 86: PSNR = 23.05, SSIM = 0.8967\n",
      "Image 87: PSNR = 21.69, SSIM = 0.9287\n",
      "Image 88: PSNR = 17.84, SSIM = 0.8926\n",
      "Image 89: PSNR = 18.34, SSIM = 0.9240\n",
      "Image 90: PSNR = 19.88, SSIM = 0.8583\n",
      "Saved batch 18 visualization to outputs_SOT_2\\batch_18.png\n",
      "Image 91: PSNR = 15.78, SSIM = 0.7664\n",
      "Image 92: PSNR = 18.55, SSIM = 0.9032\n",
      "Image 93: PSNR = 17.37, SSIM = 0.8931\n",
      "Image 94: PSNR = 18.72, SSIM = 0.8558\n",
      "Image 95: PSNR = 18.51, SSIM = 0.9324\n",
      "Saved batch 19 visualization to outputs_SOT_2\\batch_19.png\n",
      "Image 96: PSNR = 21.91, SSIM = 0.8468\n",
      "Image 97: PSNR = 19.69, SSIM = 0.9137\n",
      "Image 98: PSNR = 20.10, SSIM = 0.9012\n",
      "Image 99: PSNR = 20.53, SSIM = 0.9489\n",
      "Image 100: PSNR = 20.66, SSIM = 0.9091\n",
      "Saved batch 20 visualization to outputs_SOT_2\\batch_20.png\n",
      "Image 101: PSNR = 19.78, SSIM = 0.9183\n",
      "Image 102: PSNR = 15.68, SSIM = 0.8914\n",
      "Image 103: PSNR = 19.66, SSIM = 0.9222\n",
      "Image 104: PSNR = 23.38, SSIM = 0.9041\n",
      "Image 105: PSNR = 15.69, SSIM = 0.8605\n",
      "Saved batch 21 visualization to outputs_SOT_2\\batch_21.png\n",
      "Image 106: PSNR = 19.39, SSIM = 0.9356\n",
      "Image 107: PSNR = 18.30, SSIM = 0.9196\n",
      "Image 108: PSNR = 18.92, SSIM = 0.9042\n",
      "Image 109: PSNR = 21.18, SSIM = 0.8995\n",
      "Image 110: PSNR = 21.81, SSIM = 0.9373\n",
      "Saved batch 22 visualization to outputs_SOT_2\\batch_22.png\n",
      "Image 111: PSNR = 16.66, SSIM = 0.8714\n",
      "Image 112: PSNR = 23.94, SSIM = 0.9349\n",
      "Image 113: PSNR = 20.62, SSIM = 0.8881\n",
      "Image 114: PSNR = 19.72, SSIM = 0.9048\n",
      "Image 115: PSNR = 16.23, SSIM = 0.8494\n",
      "Saved batch 23 visualization to outputs_SOT_2\\batch_23.png\n",
      "Image 116: PSNR = 21.49, SSIM = 0.9367\n",
      "Image 117: PSNR = 20.53, SSIM = 0.9315\n",
      "Image 118: PSNR = 23.77, SSIM = 0.9400\n",
      "Image 119: PSNR = 21.42, SSIM = 0.9279\n",
      "Image 120: PSNR = 14.66, SSIM = 0.8081\n",
      "Saved batch 24 visualization to outputs_SOT_2\\batch_24.png\n",
      "Image 121: PSNR = 19.01, SSIM = 0.9254\n",
      "Image 122: PSNR = 20.17, SSIM = 0.8700\n",
      "Image 123: PSNR = 19.68, SSIM = 0.8684\n",
      "Image 124: PSNR = 22.29, SSIM = 0.9325\n",
      "Image 125: PSNR = 20.25, SSIM = 0.9128\n",
      "Saved batch 25 visualization to outputs_SOT_2\\batch_25.png\n",
      "Image 126: PSNR = 16.91, SSIM = 0.9244\n",
      "Image 127: PSNR = 16.93, SSIM = 0.8655\n",
      "Image 128: PSNR = 18.29, SSIM = 0.9389\n",
      "Image 129: PSNR = 17.97, SSIM = 0.8687\n",
      "Image 130: PSNR = 18.34, SSIM = 0.8623\n",
      "Saved batch 26 visualization to outputs_SOT_2\\batch_26.png\n",
      "Image 131: PSNR = 19.89, SSIM = 0.9289\n",
      "Image 132: PSNR = 17.97, SSIM = 0.8876\n",
      "Image 133: PSNR = 17.92, SSIM = 0.8237\n",
      "Image 134: PSNR = 22.01, SSIM = 0.9481\n",
      "Image 135: PSNR = 17.74, SSIM = 0.9005\n",
      "Saved batch 27 visualization to outputs_SOT_2\\batch_27.png\n",
      "Image 136: PSNR = 21.05, SSIM = 0.9444\n",
      "Image 137: PSNR = 18.57, SSIM = 0.8938\n",
      "Image 138: PSNR = 18.59, SSIM = 0.8630\n",
      "Image 139: PSNR = 19.24, SSIM = 0.8590\n",
      "Image 140: PSNR = 19.57, SSIM = 0.8880\n",
      "Saved batch 28 visualization to outputs_SOT_2\\batch_28.png\n",
      "Image 141: PSNR = 20.09, SSIM = 0.9136\n",
      "Image 142: PSNR = 21.29, SSIM = 0.9018\n",
      "Image 143: PSNR = 21.67, SSIM = 0.9012\n",
      "Image 144: PSNR = 18.31, SSIM = 0.8051\n",
      "Image 145: PSNR = 20.83, SSIM = 0.9167\n",
      "Saved batch 29 visualization to outputs_SOT_2\\batch_29.png\n",
      "Image 146: PSNR = 17.93, SSIM = 0.9017\n",
      "Image 147: PSNR = 18.73, SSIM = 0.9023\n",
      "Image 148: PSNR = 21.20, SSIM = 0.8796\n",
      "Image 149: PSNR = 22.31, SSIM = 0.9074\n",
      "Image 150: PSNR = 17.80, SSIM = 0.9062\n",
      "Saved batch 30 visualization to outputs_SOT_2\\batch_30.png\n",
      "Image 151: PSNR = 19.95, SSIM = 0.9016\n",
      "Image 152: PSNR = 21.16, SSIM = 0.9351\n",
      "Image 153: PSNR = 19.38, SSIM = 0.9032\n",
      "Image 154: PSNR = 19.42, SSIM = 0.8789\n",
      "Image 155: PSNR = 19.39, SSIM = 0.8888\n",
      "Saved batch 31 visualization to outputs_SOT_2\\batch_31.png\n",
      "Image 156: PSNR = 19.98, SSIM = 0.9359\n",
      "Image 157: PSNR = 24.62, SSIM = 0.9544\n",
      "Image 158: PSNR = 21.60, SSIM = 0.9085\n",
      "Image 159: PSNR = 16.56, SSIM = 0.8257\n",
      "Image 160: PSNR = 19.49, SSIM = 0.8232\n",
      "Saved batch 32 visualization to outputs_SOT_2\\batch_32.png\n",
      "Image 161: PSNR = 23.15, SSIM = 0.9213\n",
      "Image 162: PSNR = 16.76, SSIM = 0.7618\n",
      "Image 163: PSNR = 20.60, SSIM = 0.8910\n",
      "Image 164: PSNR = 20.50, SSIM = 0.9042\n",
      "Image 165: PSNR = 19.65, SSIM = 0.8899\n",
      "Saved batch 33 visualization to outputs_SOT_2\\batch_33.png\n",
      "Image 166: PSNR = 22.95, SSIM = 0.9237\n",
      "Image 167: PSNR = 21.11, SSIM = 0.9084\n",
      "Image 168: PSNR = 22.30, SSIM = 0.9157\n",
      "Image 169: PSNR = 21.44, SSIM = 0.8635\n",
      "Image 170: PSNR = 18.64, SSIM = 0.8965\n",
      "Saved batch 34 visualization to outputs_SOT_2\\batch_34.png\n",
      "Image 171: PSNR = 18.00, SSIM = 0.8702\n",
      "Image 172: PSNR = 18.98, SSIM = 0.8933\n",
      "Image 173: PSNR = 23.75, SSIM = 0.9441\n",
      "Image 174: PSNR = 19.48, SSIM = 0.9079\n",
      "Image 175: PSNR = 14.90, SSIM = 0.8148\n",
      "Saved batch 35 visualization to outputs_SOT_2\\batch_35.png\n",
      "Image 176: PSNR = 16.21, SSIM = 0.8096\n",
      "Image 177: PSNR = 20.13, SSIM = 0.9107\n",
      "Image 178: PSNR = 20.77, SSIM = 0.9455\n",
      "Image 179: PSNR = 20.04, SSIM = 0.8935\n",
      "Image 180: PSNR = 18.33, SSIM = 0.8010\n",
      "Saved batch 36 visualization to outputs_SOT_2\\batch_36.png\n",
      "Image 181: PSNR = 23.03, SSIM = 0.9556\n",
      "Image 182: PSNR = 19.63, SSIM = 0.8728\n",
      "Image 183: PSNR = 21.44, SSIM = 0.9292\n",
      "Image 184: PSNR = 17.96, SSIM = 0.8841\n",
      "Image 185: PSNR = 20.41, SSIM = 0.8960\n",
      "Saved batch 37 visualization to outputs_SOT_2\\batch_37.png\n",
      "Image 186: PSNR = 20.16, SSIM = 0.8966\n",
      "Image 187: PSNR = 23.97, SSIM = 0.9464\n",
      "Image 188: PSNR = 19.38, SSIM = 0.8399\n",
      "Image 189: PSNR = 17.11, SSIM = 0.9338\n",
      "Image 190: PSNR = 17.84, SSIM = 0.8458\n",
      "Saved batch 38 visualization to outputs_SOT_2\\batch_38.png\n",
      "Image 191: PSNR = 21.53, SSIM = 0.9496\n",
      "Image 192: PSNR = 17.19, SSIM = 0.8637\n",
      "Image 193: PSNR = 18.46, SSIM = 0.8597\n",
      "Image 194: PSNR = 19.38, SSIM = 0.9245\n",
      "Image 195: PSNR = 18.61, SSIM = 0.9080\n",
      "Saved batch 39 visualization to outputs_SOT_2\\batch_39.png\n",
      "Image 196: PSNR = 19.08, SSIM = 0.9093\n",
      "Image 197: PSNR = 21.43, SSIM = 0.9267\n",
      "Image 198: PSNR = 19.44, SSIM = 0.9134\n",
      "Image 199: PSNR = 15.77, SSIM = 0.8101\n",
      "Image 200: PSNR = 20.46, SSIM = 0.9123\n",
      "Saved batch 40 visualization to outputs_SOT_2\\batch_40.png\n",
      "Image 201: PSNR = 22.47, SSIM = 0.9358\n",
      "Image 202: PSNR = 19.28, SSIM = 0.9020\n",
      "Image 203: PSNR = 19.71, SSIM = 0.8269\n",
      "Image 204: PSNR = 21.43, SSIM = 0.8793\n",
      "Image 205: PSNR = 18.51, SSIM = 0.8563\n",
      "Saved batch 41 visualization to outputs_SOT_2\\batch_41.png\n",
      "Image 206: PSNR = 20.43, SSIM = 0.8876\n",
      "Image 207: PSNR = 22.23, SSIM = 0.9135\n",
      "Image 208: PSNR = 17.76, SSIM = 0.7030\n",
      "Image 209: PSNR = 24.05, SSIM = 0.9303\n",
      "Image 210: PSNR = 18.25, SSIM = 0.8560\n",
      "Saved batch 42 visualization to outputs_SOT_2\\batch_42.png\n",
      "Image 211: PSNR = 16.83, SSIM = 0.7620\n",
      "Image 212: PSNR = 21.31, SSIM = 0.9176\n",
      "Image 213: PSNR = 16.83, SSIM = 0.7663\n",
      "Image 214: PSNR = 21.94, SSIM = 0.9090\n",
      "Image 215: PSNR = 17.50, SSIM = 0.7694\n",
      "Saved batch 43 visualization to outputs_SOT_2\\batch_43.png\n",
      "Image 216: PSNR = 23.76, SSIM = 0.9455\n",
      "Image 217: PSNR = 17.34, SSIM = 0.8582\n",
      "Image 218: PSNR = 22.84, SSIM = 0.9306\n",
      "Image 219: PSNR = 21.57, SSIM = 0.8924\n",
      "Image 220: PSNR = 25.20, SSIM = 0.9659\n",
      "Saved batch 44 visualization to outputs_SOT_2\\batch_44.png\n",
      "Image 221: PSNR = 20.74, SSIM = 0.8973\n",
      "Image 222: PSNR = 21.65, SSIM = 0.9333\n",
      "Image 223: PSNR = 17.69, SSIM = 0.8774\n",
      "Image 224: PSNR = 19.66, SSIM = 0.9509\n",
      "Image 225: PSNR = 22.36, SSIM = 0.9561\n",
      "Saved batch 45 visualization to outputs_SOT_2\\batch_45.png\n",
      "Image 226: PSNR = 19.48, SSIM = 0.8631\n",
      "Image 227: PSNR = 24.03, SSIM = 0.9299\n",
      "Image 228: PSNR = 21.47, SSIM = 0.8587\n",
      "Image 229: PSNR = 18.25, SSIM = 0.9182\n",
      "Image 230: PSNR = 21.96, SSIM = 0.9427\n",
      "Saved batch 46 visualization to outputs_SOT_2\\batch_46.png\n",
      "Image 231: PSNR = 20.22, SSIM = 0.9327\n",
      "Image 232: PSNR = 17.81, SSIM = 0.9257\n",
      "Image 233: PSNR = 19.94, SSIM = 0.9166\n",
      "Image 234: PSNR = 20.01, SSIM = 0.9307\n",
      "Image 235: PSNR = 22.05, SSIM = 0.9220\n",
      "Saved batch 47 visualization to outputs_SOT_2\\batch_47.png\n",
      "Image 236: PSNR = 16.02, SSIM = 0.8659\n",
      "Image 237: PSNR = 17.86, SSIM = 0.8651\n",
      "Image 238: PSNR = 19.99, SSIM = 0.8781\n",
      "Image 239: PSNR = 17.60, SSIM = 0.8336\n",
      "Image 240: PSNR = 18.57, SSIM = 0.8683\n",
      "Saved batch 48 visualization to outputs_SOT_2\\batch_48.png\n",
      "Image 241: PSNR = 22.33, SSIM = 0.9420\n",
      "Image 242: PSNR = 24.34, SSIM = 0.9427\n",
      "Image 243: PSNR = 20.04, SSIM = 0.8916\n",
      "Image 244: PSNR = 18.54, SSIM = 0.8473\n",
      "Image 245: PSNR = 22.46, SSIM = 0.9269\n",
      "Saved batch 49 visualization to outputs_SOT_2\\batch_49.png\n",
      "Image 246: PSNR = 19.96, SSIM = 0.8908\n",
      "Image 247: PSNR = 23.79, SSIM = 0.9503\n",
      "Image 248: PSNR = 18.31, SSIM = 0.8561\n",
      "Image 249: PSNR = 23.56, SSIM = 0.9514\n",
      "Image 250: PSNR = 21.03, SSIM = 0.8895\n",
      "Saved batch 50 visualization to outputs_SOT_2\\batch_50.png\n",
      "Image 251: PSNR = 19.96, SSIM = 0.9293\n",
      "Image 252: PSNR = 19.75, SSIM = 0.9143\n",
      "Image 253: PSNR = 20.17, SSIM = 0.8895\n",
      "Image 254: PSNR = 18.82, SSIM = 0.9167\n",
      "Image 255: PSNR = 18.81, SSIM = 0.9105\n",
      "Saved batch 51 visualization to outputs_SOT_2\\batch_51.png\n",
      "Image 256: PSNR = 23.23, SSIM = 0.9489\n",
      "Image 257: PSNR = 21.12, SSIM = 0.9300\n",
      "Image 258: PSNR = 20.10, SSIM = 0.8899\n",
      "Image 259: PSNR = 17.21, SSIM = 0.9019\n",
      "Image 260: PSNR = 18.48, SSIM = 0.9222\n",
      "Saved batch 52 visualization to outputs_SOT_2\\batch_52.png\n",
      "Image 261: PSNR = 20.75, SSIM = 0.9068\n",
      "Image 262: PSNR = 18.82, SSIM = 0.9212\n",
      "Image 263: PSNR = 19.64, SSIM = 0.9299\n",
      "Image 264: PSNR = 19.45, SSIM = 0.8693\n",
      "Image 265: PSNR = 19.44, SSIM = 0.8854\n",
      "Saved batch 53 visualization to outputs_SOT_2\\batch_53.png\n",
      "Image 266: PSNR = 22.91, SSIM = 0.9414\n",
      "Image 267: PSNR = 19.25, SSIM = 0.8746\n",
      "Image 268: PSNR = 19.28, SSIM = 0.8383\n",
      "Image 269: PSNR = 21.96, SSIM = 0.8100\n",
      "Image 270: PSNR = 20.26, SSIM = 0.9108\n",
      "Saved batch 54 visualization to outputs_SOT_2\\batch_54.png\n",
      "Image 271: PSNR = 17.43, SSIM = 0.9204\n",
      "Image 272: PSNR = 20.25, SSIM = 0.9486\n",
      "Image 273: PSNR = 21.65, SSIM = 0.9442\n",
      "Image 274: PSNR = 22.62, SSIM = 0.9329\n",
      "Image 275: PSNR = 19.36, SSIM = 0.9050\n",
      "Saved batch 55 visualization to outputs_SOT_2\\batch_55.png\n",
      "Image 276: PSNR = 17.50, SSIM = 0.8818\n",
      "Image 277: PSNR = 22.71, SSIM = 0.9392\n",
      "Image 278: PSNR = 23.15, SSIM = 0.9369\n",
      "Image 279: PSNR = 22.68, SSIM = 0.9279\n",
      "Image 280: PSNR = 16.69, SSIM = 0.8400\n",
      "Saved batch 56 visualization to outputs_SOT_2\\batch_56.png\n",
      "Image 281: PSNR = 21.93, SSIM = 0.9245\n",
      "Image 282: PSNR = 20.57, SSIM = 0.9385\n",
      "Image 283: PSNR = 16.05, SSIM = 0.8872\n",
      "Image 284: PSNR = 20.22, SSIM = 0.9471\n",
      "Image 285: PSNR = 17.77, SSIM = 0.8689\n",
      "Saved batch 57 visualization to outputs_SOT_2\\batch_57.png\n",
      "Image 286: PSNR = 19.43, SSIM = 0.8792\n",
      "Image 287: PSNR = 21.42, SSIM = 0.9118\n",
      "Image 288: PSNR = 20.22, SSIM = 0.8963\n",
      "Image 289: PSNR = 18.07, SSIM = 0.9254\n",
      "Image 290: PSNR = 19.07, SSIM = 0.8609\n",
      "Saved batch 58 visualization to outputs_SOT_2\\batch_58.png\n",
      "Image 291: PSNR = 18.10, SSIM = 0.8200\n",
      "Image 292: PSNR = 17.84, SSIM = 0.8581\n",
      "Image 293: PSNR = 15.08, SSIM = 0.7394\n",
      "Image 294: PSNR = 19.48, SSIM = 0.8836\n",
      "Image 295: PSNR = 19.37, SSIM = 0.9118\n",
      "Saved batch 59 visualization to outputs_SOT_2\\batch_59.png\n",
      "Image 296: PSNR = 19.62, SSIM = 0.9222\n",
      "Image 297: PSNR = 16.04, SSIM = 0.7062\n",
      "Image 298: PSNR = 15.76, SSIM = 0.8294\n",
      "Image 299: PSNR = 16.22, SSIM = 0.7771\n",
      "Image 300: PSNR = 19.07, SSIM = 0.8211\n",
      "Saved batch 60 visualization to outputs_SOT_2\\batch_60.png\n",
      "Image 301: PSNR = 17.09, SSIM = 0.7420\n",
      "Image 302: PSNR = 21.01, SSIM = 0.9103\n",
      "Image 303: PSNR = 18.92, SSIM = 0.9104\n",
      "Image 304: PSNR = 17.16, SSIM = 0.8934\n",
      "Image 305: PSNR = 22.18, SSIM = 0.9444\n",
      "Saved batch 61 visualization to outputs_SOT_2\\batch_61.png\n",
      "Image 306: PSNR = 18.15, SSIM = 0.8791\n",
      "Image 307: PSNR = 16.38, SSIM = 0.6996\n",
      "Image 308: PSNR = 19.20, SSIM = 0.8516\n",
      "Image 309: PSNR = 19.16, SSIM = 0.8970\n",
      "Image 310: PSNR = 16.95, SSIM = 0.7814\n",
      "Saved batch 62 visualization to outputs_SOT_2\\batch_62.png\n",
      "Image 311: PSNR = 19.78, SSIM = 0.8404\n",
      "Image 312: PSNR = 20.23, SSIM = 0.8963\n",
      "Image 313: PSNR = 15.44, SSIM = 0.6751\n",
      "Image 314: PSNR = 18.58, SSIM = 0.7911\n",
      "Image 315: PSNR = 21.94, SSIM = 0.8668\n",
      "Saved batch 63 visualization to outputs_SOT_2\\batch_63.png\n",
      "Image 316: PSNR = 19.45, SSIM = 0.9129\n",
      "Image 317: PSNR = 19.81, SSIM = 0.8622\n",
      "Image 318: PSNR = 22.80, SSIM = 0.9321\n",
      "Image 319: PSNR = 26.25, SSIM = 0.9729\n",
      "Image 320: PSNR = 22.80, SSIM = 0.9487\n",
      "Saved batch 64 visualization to outputs_SOT_2\\batch_64.png\n",
      "Image 321: PSNR = 18.97, SSIM = 0.9331\n",
      "Image 322: PSNR = 18.07, SSIM = 0.8367\n",
      "Image 323: PSNR = 22.95, SSIM = 0.9391\n",
      "Image 324: PSNR = 19.81, SSIM = 0.9029\n",
      "Image 325: PSNR = 18.88, SSIM = 0.9240\n",
      "Saved batch 65 visualization to outputs_SOT_2\\batch_65.png\n",
      "Image 326: PSNR = 20.59, SSIM = 0.9200\n",
      "Image 327: PSNR = 22.62, SSIM = 0.9495\n",
      "Image 328: PSNR = 23.48, SSIM = 0.9445\n",
      "Image 329: PSNR = 21.28, SSIM = 0.9261\n",
      "Image 330: PSNR = 21.29, SSIM = 0.9288\n",
      "Saved batch 66 visualization to outputs_SOT_2\\batch_66.png\n",
      "Image 331: PSNR = 21.40, SSIM = 0.9188\n",
      "Image 332: PSNR = 20.11, SSIM = 0.9145\n",
      "Image 333: PSNR = 21.44, SSIM = 0.9190\n",
      "Image 334: PSNR = 18.95, SSIM = 0.9250\n",
      "Image 335: PSNR = 26.37, SSIM = 0.9659\n",
      "Saved batch 67 visualization to outputs_SOT_2\\batch_67.png\n",
      "Image 336: PSNR = 21.12, SSIM = 0.8970\n",
      "Image 337: PSNR = 21.88, SSIM = 0.9114\n",
      "Image 338: PSNR = 21.65, SSIM = 0.9336\n",
      "Image 339: PSNR = 16.03, SSIM = 0.8664\n",
      "Image 340: PSNR = 22.67, SSIM = 0.9039\n",
      "Saved batch 68 visualization to outputs_SOT_2\\batch_68.png\n",
      "Image 341: PSNR = 21.74, SSIM = 0.9207\n",
      "Image 342: PSNR = 18.98, SSIM = 0.8918\n",
      "Image 343: PSNR = 22.45, SSIM = 0.9336\n",
      "Image 344: PSNR = 18.83, SSIM = 0.9305\n",
      "Image 345: PSNR = 17.68, SSIM = 0.9175\n",
      "Saved batch 69 visualization to outputs_SOT_2\\batch_69.png\n",
      "Image 346: PSNR = 19.32, SSIM = 0.9289\n",
      "Image 347: PSNR = 19.65, SSIM = 0.8850\n",
      "Image 348: PSNR = 22.41, SSIM = 0.9298\n",
      "Image 349: PSNR = 21.57, SSIM = 0.9331\n",
      "Image 350: PSNR = 16.89, SSIM = 0.8999\n",
      "Saved batch 70 visualization to outputs_SOT_2\\batch_70.png\n",
      "Image 351: PSNR = 24.49, SSIM = 0.9568\n",
      "Image 352: PSNR = 23.06, SSIM = 0.9385\n",
      "Image 353: PSNR = 19.52, SSIM = 0.8865\n",
      "Image 354: PSNR = 21.00, SSIM = 0.9219\n",
      "Image 355: PSNR = 19.77, SSIM = 0.8522\n",
      "Saved batch 71 visualization to outputs_SOT_2\\batch_71.png\n",
      "Image 356: PSNR = 18.41, SSIM = 0.8398\n",
      "Image 357: PSNR = 18.90, SSIM = 0.8238\n",
      "Image 358: PSNR = 21.30, SSIM = 0.9230\n",
      "Image 359: PSNR = 18.72, SSIM = 0.9229\n",
      "Image 360: PSNR = 23.91, SSIM = 0.9489\n",
      "Saved batch 72 visualization to outputs_SOT_2\\batch_72.png\n",
      "Image 361: PSNR = 23.86, SSIM = 0.9438\n",
      "Image 362: PSNR = 20.04, SSIM = 0.9018\n",
      "Image 363: PSNR = 20.71, SSIM = 0.9295\n",
      "Image 364: PSNR = 21.61, SSIM = 0.9344\n",
      "Image 365: PSNR = 15.09, SSIM = 0.7883\n",
      "Saved batch 73 visualization to outputs_SOT_2\\batch_73.png\n",
      "Image 366: PSNR = 13.35, SSIM = 0.7090\n",
      "Image 367: PSNR = 16.77, SSIM = 0.8532\n",
      "Image 368: PSNR = 16.96, SSIM = 0.7798\n",
      "Image 369: PSNR = 20.05, SSIM = 0.8405\n",
      "Image 370: PSNR = 16.99, SSIM = 0.8828\n",
      "Saved batch 74 visualization to outputs_SOT_2\\batch_74.png\n",
      "Image 371: PSNR = 24.18, SSIM = 0.9194\n",
      "Image 372: PSNR = 21.20, SSIM = 0.9127\n",
      "Image 373: PSNR = 14.36, SSIM = 0.7313\n",
      "Image 374: PSNR = 19.62, SSIM = 0.9077\n",
      "Image 375: PSNR = 18.91, SSIM = 0.8895\n",
      "Saved batch 75 visualization to outputs_SOT_2\\batch_75.png\n",
      "Image 376: PSNR = 20.36, SSIM = 0.8920\n",
      "Image 377: PSNR = 17.14, SSIM = 0.8267\n",
      "Image 378: PSNR = 16.61, SSIM = 0.8313\n",
      "Image 379: PSNR = 16.75, SSIM = 0.8334\n",
      "Image 380: PSNR = 20.27, SSIM = 0.9169\n",
      "Saved batch 76 visualization to outputs_SOT_2\\batch_76.png\n",
      "Image 381: PSNR = 19.78, SSIM = 0.8927\n",
      "Image 382: PSNR = 18.63, SSIM = 0.8999\n",
      "Image 383: PSNR = 18.47, SSIM = 0.8603\n",
      "Image 384: PSNR = 18.44, SSIM = 0.7734\n",
      "Image 385: PSNR = 17.53, SSIM = 0.8927\n",
      "Saved batch 77 visualization to outputs_SOT_2\\batch_77.png\n",
      "Image 386: PSNR = 19.57, SSIM = 0.8362\n",
      "Image 387: PSNR = 21.24, SSIM = 0.9253\n",
      "Image 388: PSNR = 21.75, SSIM = 0.9261\n",
      "Image 389: PSNR = 19.97, SSIM = 0.9380\n",
      "Image 390: PSNR = 19.26, SSIM = 0.8550\n",
      "Saved batch 78 visualization to outputs_SOT_2\\batch_78.png\n",
      "Image 391: PSNR = 24.18, SSIM = 0.9395\n",
      "Image 392: PSNR = 15.15, SSIM = 0.7608\n",
      "Image 393: PSNR = 20.73, SSIM = 0.9315\n",
      "Image 394: PSNR = 22.22, SSIM = 0.9272\n",
      "Image 395: PSNR = 19.34, SSIM = 0.9216\n",
      "Saved batch 79 visualization to outputs_SOT_2\\batch_79.png\n",
      "Image 396: PSNR = 18.87, SSIM = 0.9215\n",
      "Image 397: PSNR = 17.03, SSIM = 0.8876\n",
      "Image 398: PSNR = 19.89, SSIM = 0.8136\n",
      "Image 399: PSNR = 23.91, SSIM = 0.9491\n",
      "Image 400: PSNR = 14.85, SSIM = 0.7162\n",
      "Saved batch 80 visualization to outputs_SOT_2\\batch_80.png\n",
      "Image 401: PSNR = 16.44, SSIM = 0.8063\n",
      "Image 402: PSNR = 20.49, SSIM = 0.8765\n",
      "Image 403: PSNR = 17.63, SSIM = 0.8581\n",
      "Image 404: PSNR = 16.41, SSIM = 0.8700\n",
      "Image 405: PSNR = 22.18, SSIM = 0.9281\n",
      "Saved batch 81 visualization to outputs_SOT_2\\batch_81.png\n",
      "Image 406: PSNR = 19.75, SSIM = 0.8563\n",
      "Image 407: PSNR = 15.95, SSIM = 0.7825\n",
      "Image 408: PSNR = 16.39, SSIM = 0.8965\n",
      "Image 409: PSNR = 18.21, SSIM = 0.9170\n",
      "Image 410: PSNR = 21.79, SSIM = 0.9000\n",
      "Saved batch 82 visualization to outputs_SOT_2\\batch_82.png\n",
      "Image 411: PSNR = 19.89, SSIM = 0.9233\n",
      "Image 412: PSNR = 20.78, SSIM = 0.9105\n",
      "Image 413: PSNR = 16.30, SSIM = 0.7953\n",
      "Image 414: PSNR = 16.28, SSIM = 0.8643\n",
      "Image 415: PSNR = 19.11, SSIM = 0.8619\n",
      "Saved batch 83 visualization to outputs_SOT_2\\batch_83.png\n",
      "Image 416: PSNR = 18.00, SSIM = 0.8838\n",
      "Image 417: PSNR = 20.28, SSIM = 0.8705\n",
      "Image 418: PSNR = 18.85, SSIM = 0.8990\n",
      "Image 419: PSNR = 24.39, SSIM = 0.9433\n",
      "Image 420: PSNR = 18.87, SSIM = 0.8416\n",
      "Saved batch 84 visualization to outputs_SOT_2\\batch_84.png\n",
      "Image 421: PSNR = 18.12, SSIM = 0.8398\n",
      "Image 422: PSNR = 15.04, SSIM = 0.8600\n",
      "Image 423: PSNR = 19.00, SSIM = 0.9076\n",
      "Image 424: PSNR = 19.19, SSIM = 0.8708\n",
      "Image 425: PSNR = 20.47, SSIM = 0.9016\n",
      "Saved batch 85 visualization to outputs_SOT_2\\batch_85.png\n",
      "Image 426: PSNR = 18.27, SSIM = 0.9386\n",
      "Image 427: PSNR = 19.77, SSIM = 0.8824\n",
      "Image 428: PSNR = 18.24, SSIM = 0.8525\n",
      "Image 429: PSNR = 19.63, SSIM = 0.8807\n",
      "Image 430: PSNR = 17.69, SSIM = 0.8945\n",
      "Saved batch 86 visualization to outputs_SOT_2\\batch_86.png\n",
      "Image 431: PSNR = 17.38, SSIM = 0.8800\n",
      "Image 432: PSNR = 23.14, SSIM = 0.9328\n",
      "Image 433: PSNR = 18.93, SSIM = 0.9450\n",
      "Image 434: PSNR = 19.05, SSIM = 0.8666\n",
      "Image 435: PSNR = 19.20, SSIM = 0.8956\n",
      "Saved batch 87 visualization to outputs_SOT_2\\batch_87.png\n",
      "Image 436: PSNR = 19.55, SSIM = 0.9298\n",
      "Image 437: PSNR = 20.35, SSIM = 0.9087\n",
      "Image 438: PSNR = 17.14, SSIM = 0.7976\n",
      "Image 439: PSNR = 26.20, SSIM = 0.9608\n",
      "Image 440: PSNR = 21.59, SSIM = 0.8930\n",
      "Saved batch 88 visualization to outputs_SOT_2\\batch_88.png\n",
      "Image 441: PSNR = 20.28, SSIM = 0.9256\n",
      "Image 442: PSNR = 18.52, SSIM = 0.8718\n",
      "Image 443: PSNR = 20.14, SSIM = 0.9247\n",
      "Image 444: PSNR = 18.81, SSIM = 0.9114\n",
      "Image 445: PSNR = 20.03, SSIM = 0.9345\n",
      "Saved batch 89 visualization to outputs_SOT_2\\batch_89.png\n",
      "Image 446: PSNR = 17.33, SSIM = 0.8980\n",
      "Image 447: PSNR = 22.49, SSIM = 0.9059\n",
      "Image 448: PSNR = 18.35, SSIM = 0.8604\n",
      "Image 449: PSNR = 22.19, SSIM = 0.9330\n",
      "Image 450: PSNR = 19.81, SSIM = 0.8018\n",
      "Saved batch 90 visualization to outputs_SOT_2\\batch_90.png\n",
      "Image 451: PSNR = 19.69, SSIM = 0.8738\n",
      "Image 452: PSNR = 19.02, SSIM = 0.8852\n",
      "Image 453: PSNR = 18.03, SSIM = 0.8594\n",
      "Image 454: PSNR = 19.95, SSIM = 0.8638\n",
      "Image 455: PSNR = 19.17, SSIM = 0.8749\n",
      "Saved batch 91 visualization to outputs_SOT_2\\batch_91.png\n",
      "Image 456: PSNR = 19.20, SSIM = 0.8807\n",
      "Image 457: PSNR = 18.52, SSIM = 0.8660\n",
      "Image 458: PSNR = 15.22, SSIM = 0.6745\n",
      "Image 459: PSNR = 21.21, SSIM = 0.8579\n",
      "Image 460: PSNR = 19.40, SSIM = 0.8819\n",
      "Saved batch 92 visualization to outputs_SOT_2\\batch_92.png\n",
      "Image 461: PSNR = 23.38, SSIM = 0.9641\n",
      "Image 462: PSNR = 14.80, SSIM = 0.7075\n",
      "Image 463: PSNR = 16.04, SSIM = 0.8574\n",
      "Image 464: PSNR = 20.75, SSIM = 0.9277\n",
      "Image 465: PSNR = 22.58, SSIM = 0.9616\n",
      "Saved batch 93 visualization to outputs_SOT_2\\batch_93.png\n",
      "Image 466: PSNR = 19.84, SSIM = 0.8927\n",
      "Image 467: PSNR = 17.14, SSIM = 0.8610\n",
      "Image 468: PSNR = 14.86, SSIM = 0.8810\n",
      "Image 469: PSNR = 14.95, SSIM = 0.8310\n",
      "Image 470: PSNR = 18.23, SSIM = 0.9138\n",
      "Saved batch 94 visualization to outputs_SOT_2\\batch_94.png\n",
      "Image 471: PSNR = 18.40, SSIM = 0.9167\n",
      "Image 472: PSNR = 20.26, SSIM = 0.8808\n",
      "Image 473: PSNR = 19.36, SSIM = 0.8958\n",
      "Image 474: PSNR = 18.51, SSIM = 0.9301\n",
      "Image 475: PSNR = 21.74, SSIM = 0.9538\n",
      "Saved batch 95 visualization to outputs_SOT_2\\batch_95.png\n",
      "Image 476: PSNR = 17.46, SSIM = 0.8654\n",
      "Image 477: PSNR = 20.90, SSIM = 0.9404\n",
      "Image 478: PSNR = 19.80, SSIM = 0.9425\n",
      "Image 479: PSNR = 17.76, SSIM = 0.9217\n",
      "Image 480: PSNR = 18.09, SSIM = 0.9319\n",
      "Saved batch 96 visualization to outputs_SOT_2\\batch_96.png\n",
      "Image 481: PSNR = 21.17, SSIM = 0.9001\n",
      "Image 482: PSNR = 19.24, SSIM = 0.9236\n",
      "Image 483: PSNR = 20.40, SSIM = 0.9082\n",
      "Image 484: PSNR = 18.04, SSIM = 0.8983\n",
      "Image 485: PSNR = 15.94, SSIM = 0.8691\n",
      "Saved batch 97 visualization to outputs_SOT_2\\batch_97.png\n",
      "Image 486: PSNR = 21.79, SSIM = 0.9165\n",
      "Image 487: PSNR = 20.58, SSIM = 0.9055\n",
      "Image 488: PSNR = 22.47, SSIM = 0.9348\n",
      "Image 489: PSNR = 18.35, SSIM = 0.8564\n",
      "Image 490: PSNR = 18.20, SSIM = 0.8955\n",
      "Saved batch 98 visualization to outputs_SOT_2\\batch_98.png\n",
      "Image 491: PSNR = 19.74, SSIM = 0.9045\n",
      "Image 492: PSNR = 19.91, SSIM = 0.9186\n",
      "Image 493: PSNR = 18.82, SSIM = 0.9020\n",
      "Image 494: PSNR = 19.93, SSIM = 0.9019\n",
      "Image 495: PSNR = 17.45, SSIM = 0.8970\n",
      "Saved batch 99 visualization to outputs_SOT_2\\batch_99.png\n",
      "Image 496: PSNR = 17.13, SSIM = 0.9184\n",
      "Image 497: PSNR = 21.56, SSIM = 0.9389\n",
      "Image 498: PSNR = 18.50, SSIM = 0.9001\n",
      "Image 499: PSNR = 20.63, SSIM = 0.9097\n",
      "Image 500: PSNR = 18.84, SSIM = 0.8989\n",
      "Saved batch 100 visualization to outputs_SOT_2\\batch_100.png\n",
      "Average PSNR: 19.60\n",
      "Average SSIM: 0.8916\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim \n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset Class\n",
    "class PairedImageDataset(Dataset):\n",
    "    def __init__(self, root_folder, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_folder (str): Path to the dataset folder containing 'clear' and 'hazy' subfolders.\n",
    "            transform (callable, optional): Transform to apply to the images.\n",
    "        \"\"\"\n",
    "        self.clear_folder = os.path.join(root_folder, \"clear\")\n",
    "        self.hazy_folder = os.path.join(root_folder, \"hazy\")\n",
    "        \n",
    "        # Filter hazy images ending with '_5.png' and generate corresponding clear image names\n",
    "        self.hazy_images = sorted([f for f in os.listdir(self.hazy_folder) if f.endswith('.jpg')])\n",
    "        self.clear_images = [f\"{f.split('_')[0]}.png\" for f in self.hazy_images]\n",
    "        \n",
    "        for clear_img in self.clear_images:\n",
    "            if not os.path.exists(os.path.join(self.clear_folder, clear_img)):\n",
    "                raise FileNotFoundError(f\"Missing clear image: {clear_img}\")\n",
    "        \n",
    "        # Default transformations\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((256, 256)),  # Resize to fixed size\n",
    "                transforms.ToTensor(),         # Convert to tensor\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hazy_path = os.path.join(self.hazy_folder, self.hazy_images[idx])\n",
    "        clear_path = os.path.join(self.clear_folder, self.clear_images[idx])\n",
    "        \n",
    "        hazy_img = Image.open(hazy_path).convert(\"RGB\")\n",
    "        clear_img = Image.open(clear_path).convert(\"RGB\")\n",
    "        \n",
    "        hazy_img = self.transform(hazy_img)\n",
    "        clear_img = self.transform(clear_img)\n",
    "        \n",
    "        return hazy_img, clear_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hazy_images)\n",
    "\n",
    "# Dehazing Model (Dummy Example)\n",
    "class DehazingModel(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * 0.9  # Replace with actual model logic\n",
    "\n",
    "# Path setup\n",
    "root_folder = \"./outdoor\"  # Dataset folder containing 'clear' and 'hazy'\n",
    "output_dir = \"outputs_SOT_2\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize dataset and dataloader\n",
    "dataset = PairedImageDataset(root_folder)\n",
    "data_loader = DataLoader(dataset, batch_size=5, shuffle=False)\n",
    "\n",
    "# Load Model\n",
    "model = AODNet() \n",
    "weights_path = \"./model/model-10.ckpt\"\n",
    "model.load_state_dict(torch.load(weights_path, map_location=device), strict=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Metrics Initialization\n",
    "total_psnr = 0\n",
    "total_ssim = 0\n",
    "num_images = 0\n",
    "\n",
    "# Process and Evaluate\n",
    "for idx, (hazy_imgs, clear_imgs) in enumerate(data_loader):\n",
    "    hazy_imgs = hazy_imgs.to(device)\n",
    "    clear_imgs = clear_imgs.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dehazed_imgs = model(hazy_imgs)\n",
    "\n",
    "    # Visualization and Metrics Calculation\n",
    "    fig, axs = plt.subplots(5, 3, figsize=(8, 13))\n",
    "    axs[0, 0].set_title(\"Hazy Image\")\n",
    "    axs[0, 1].set_title(\"Dehazed Image\")\n",
    "    axs[0, 2].set_title(\"Clear Image\")\n",
    "\n",
    "    for i in range(len(hazy_imgs)):\n",
    "        # Convert tensors to numpy for visualization and metrics\n",
    "        hazy_img_np = hazy_imgs[i].cpu().permute(1, 2, 0).numpy()\n",
    "        dehazed_img_np = dehazed_imgs[i].cpu().permute(1, 2, 0).numpy()\n",
    "        clear_img_np = clear_imgs[i].cpu().permute(1, 2, 0).numpy()\n",
    "\n",
    "        # Clip values to valid range\n",
    "        hazy_img_np = np.clip(hazy_img_np, 0, 1)\n",
    "        dehazed_img_np = np.clip(dehazed_img_np, 0, 1)\n",
    "        clear_img_np = np.clip(clear_img_np, 0, 1)\n",
    "\n",
    "        # Compute PSNR and SSIM\n",
    "        psnr_value = psnr(clear_img_np, dehazed_img_np, data_range=1.0)\n",
    "        ssim_value = ssim(clear_img_np, dehazed_img_np, channel_axis=-1, data_range=1.0)\n",
    "\n",
    "        total_psnr += psnr_value\n",
    "        total_ssim += ssim_value\n",
    "        num_images += 1\n",
    "\n",
    "        # Plot images\n",
    "        axs[i, 0].imshow(hazy_img_np)\n",
    "        axs[i, 1].imshow(dehazed_img_np)\n",
    "        axs[i, 2].imshow(clear_img_np)\n",
    "        axs[i, 0].axis(\"off\")\n",
    "        axs[i, 1].axis(\"off\")\n",
    "        axs[i, 2].axis(\"off\")\n",
    "\n",
    "        print(f\"Image {num_images}: PSNR = {psnr_value:.2f}, SSIM = {ssim_value:.4f}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save visualization\n",
    "    save_path = os.path.join(output_dir, f\"batch_{idx + 1}.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Saved batch {idx + 1} visualization to {save_path}\")\n",
    "\n",
    "# Final Metrics\n",
    "average_psnr = total_psnr / num_images\n",
    "average_ssim = total_ssim / num_images\n",
    "print(f\"Average PSNR: {average_psnr:.2f}\")\n",
    "print(f\"Average SSIM: {average_ssim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Smoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul chauhan\\AppData\\Local\\Temp\\ipykernel_37400\\380405263.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weights_path, map_location=device), strict=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1: PSNR = 11.61, SSIM = 0.4425\n",
      "Image 2: PSNR = 11.74, SSIM = 0.3760\n",
      "Image 3: PSNR = 13.47, SSIM = 0.4705\n",
      "Image 4: PSNR = 12.28, SSIM = 0.4356\n",
      "Image 5: PSNR = 11.09, SSIM = 0.3935\n",
      "Saved batch 1 visualization to outputs_Smoke_test\\batch_1.png\n",
      "Image 6: PSNR = 8.88, SSIM = 0.0751\n",
      "Image 7: PSNR = 11.65, SSIM = 0.4768\n",
      "Image 8: PSNR = 11.04, SSIM = 0.4000\n",
      "Image 9: PSNR = 12.61, SSIM = 0.4146\n",
      "Image 10: PSNR = 12.36, SSIM = 0.3986\n",
      "Saved batch 2 visualization to outputs_Smoke_test\\batch_2.png\n",
      "Image 11: PSNR = 11.99, SSIM = 0.2733\n",
      "Image 12: PSNR = 12.10, SSIM = 0.4816\n",
      "Saved batch 3 visualization to outputs_Smoke_test\\batch_3.png\n",
      "Average PSNR: 11.73\n",
      "Average SSIM: 0.3865\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim \n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset Class\n",
    "class PairedImageDataset(Dataset):\n",
    "    def __init__(self, root_folder, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_folder (str): Path to the dataset folder containing 'clear' and 'hazy' subfolders.\n",
    "            transform (callable, optional): Transform to apply to the images.\n",
    "        \"\"\"\n",
    "    \n",
    "        self.clear_folder = os.path.join(root_folder, \"clean\")\n",
    "        self.hazy_folder = os.path.join(root_folder, \"hazy\")\n",
    "        \n",
    "        # Filter hazy images ending with '_5.png' and generate corresponding clear image names\n",
    "        self.hazy_images = sorted([f for f in os.listdir(self.hazy_folder) if f.endswith('.png')])\n",
    "        self.clear_images = [f\"{f}\" for f in self.hazy_images]\n",
    "        \n",
    "        for clear_img in self.clear_images:\n",
    "            if not os.path.exists(os.path.join(self.clear_folder, clear_img)):\n",
    "                raise FileNotFoundError(f\"Missing clear image: {clear_img}\")\n",
    "        \n",
    "        # Default transformations\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((256, 256)),  # Resize to fixed size\n",
    "                transforms.ToTensor(),         # Convert to tensor\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hazy_path = os.path.join(self.hazy_folder, self.hazy_images[idx])\n",
    "        clear_path = os.path.join(self.clear_folder, self.clear_images[idx])\n",
    "        \n",
    "        hazy_img = Image.open(hazy_path).convert(\"RGB\")\n",
    "        clear_img = Image.open(clear_path).convert(\"RGB\")\n",
    "        \n",
    "        hazy_img = self.transform(hazy_img)\n",
    "        clear_img = self.transform(clear_img)\n",
    "        \n",
    "        return hazy_img, clear_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hazy_images)\n",
    "\n",
    "# Dehazing Model (Dummy Example)\n",
    "class DehazingModel(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * 0.9  # Replace with actual model logic\n",
    "\n",
    "# Path setup\n",
    "root_folder = \"./Smoke\"  # Dataset folder containing 'clear' and 'hazy'\n",
    "output_dir = \"outputs_Smoke_test\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize dataset and dataloader\n",
    "dataset = PairedImageDataset(root_folder)\n",
    "data_loader = DataLoader(dataset, batch_size=5, shuffle=False)\n",
    "\n",
    "# Load Model\n",
    "model = AODNet() \n",
    "weights_path = \"./model/model-10.ckpt\"\n",
    "model.load_state_dict(torch.load(weights_path, map_location=device), strict=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Metrics Initialization\n",
    "total_psnr = 0\n",
    "total_ssim = 0\n",
    "num_images = 0\n",
    "\n",
    "# Process and Evaluate\n",
    "for idx, (hazy_imgs, clear_imgs) in enumerate(data_loader):\n",
    "    hazy_imgs = hazy_imgs.to(device)\n",
    "    clear_imgs = clear_imgs.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dehazed_imgs = model(hazy_imgs)\n",
    "\n",
    "    # Visualization and Metrics Calculation\n",
    "    fig, axs = plt.subplots(5, 3, figsize=(8, 13))\n",
    "    axs[0, 0].set_title(\"Hazy Image\")\n",
    "    axs[0, 1].set_title(\"Dehazed Image\")\n",
    "    axs[0, 2].set_title(\"Clear Image\")\n",
    "\n",
    "    for i in range(len(hazy_imgs)):\n",
    "        # Convert tensors to numpy for visualization and metrics\n",
    "        hazy_img_np = hazy_imgs[i].cpu().permute(1, 2, 0).numpy()\n",
    "        dehazed_img_np = dehazed_imgs[i].cpu().permute(1, 2, 0).numpy()\n",
    "        clear_img_np = clear_imgs[i].cpu().permute(1, 2, 0).numpy()\n",
    "\n",
    "        # Clip values to valid range\n",
    "        hazy_img_np = np.clip(hazy_img_np, 0, 1)\n",
    "        dehazed_img_np = np.clip(dehazed_img_np, 0, 1)\n",
    "        clear_img_np = np.clip(clear_img_np, 0, 1)\n",
    "\n",
    "        # Compute PSNR and SSIM\n",
    "        psnr_value = psnr(clear_img_np, dehazed_img_np, data_range=1.0)\n",
    "        ssim_value = ssim(clear_img_np, dehazed_img_np, channel_axis=-1, data_range=1.0)\n",
    "\n",
    "        total_psnr += psnr_value\n",
    "        total_ssim += ssim_value\n",
    "        num_images += 1\n",
    "\n",
    "        # Plot images\n",
    "        axs[i, 0].imshow(hazy_img_np)\n",
    "        axs[i, 1].imshow(dehazed_img_np)\n",
    "        axs[i, 2].imshow(clear_img_np)\n",
    "        axs[i, 0].axis(\"off\")\n",
    "        axs[i, 1].axis(\"off\")\n",
    "        axs[i, 2].axis(\"off\")\n",
    "\n",
    "        print(f\"Image {num_images}: PSNR = {psnr_value:.2f}, SSIM = {ssim_value:.4f}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save visualization\n",
    "    save_path = os.path.join(output_dir, f\"batch_{idx + 1}.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Saved batch {idx + 1} visualization to {save_path}\")\n",
    "\n",
    "# Final Metrics\n",
    "average_psnr = total_psnr / num_images\n",
    "average_ssim = total_ssim / num_images\n",
    "print(f\"Average PSNR: {average_psnr:.2f}\")\n",
    "print(f\"Average SSIM: {average_ssim:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
